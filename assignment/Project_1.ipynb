{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python [default]",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "name": "Project_1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ricglz/CE888_activities/blob/main/assignment/Project_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKioRsqnkdCH"
      },
      "source": [
        "## Install dependencies\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jR0i3ECTUmmx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16eb9522-6929-486b-859f-12a66bcfee12"
      },
      "source": [
        "!pip install torch torchvision skorch timm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.7.0+cu101)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.8.1+cu101)\n",
            "Requirement already satisfied: skorch in /usr/local/lib/python3.6/dist-packages (0.9.0)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.6/dist-packages (0.3.4)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch) (0.8)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch) (3.7.4.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch) (0.16.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (7.0.0)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.6/dist-packages (from skorch) (0.8.7)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from skorch) (0.22.2.post1)\n",
            "Requirement already satisfied: tqdm>=4.14.0 in /usr/local/lib/python3.6/dist-packages (from skorch) (4.41.1)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from skorch) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.19.1->skorch) (1.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bu0y8g8gUmmz"
      },
      "source": [
        "## Preparations\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4p6zCFXskagK"
      },
      "source": [
        "\n",
        "Before we begin, lets mount the google drive to later on read information from it:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NeqA16HnUmmz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28922e42-e4bb-48c4-a60b-0993c9384de7"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive_path = '/content/gdrive'\n",
        "drive.mount(drive_path, force_remount=False)\n",
        "drive_path += '/MyDrive'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3XqUaGeNebYT"
      },
      "source": [
        "Next we will set the seeds in everything to make this as deterministic as possible"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuutjrXRcWd7"
      },
      "source": [
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "seed = 42\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iixFi55mUmm1"
      },
      "source": [
        "## Gather the dataset\n",
        "\n",
        "For this we will create both our training _(which later on will be splitted into actual training an validation)_ and testing dataset.\n",
        "\n",
        "Pytorch also allows us to have transformations like the resize and the normalization. The normalization used are [the mean and std of the ImageNet dataset](https://github.com/rwightman/pytorch-image-models/blob/master/timm/data/constants.py)\n",
        "\n",
        "----"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDmTwvy1Umm2"
      },
      "source": [
        "import torchvision.transforms as T\n",
        "from os import path\n",
        "\n",
        "data_dir = path.join(drive_path, 'Essex/Datasets/Flame')\n",
        "resize = T.Resize((254, 254))\n",
        "normalize = T.Normalize([0.485, 0.456, 0.406], \n",
        "                         [0.229, 0.224, 0.225])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HStp5BCmbkI"
      },
      "source": [
        "train_transforms = T.Compose([\n",
        "  resize,\n",
        "  T.ColorJitter(brightness=0.25, contrast=0.25),\n",
        "  T.RandomRotation(degrees=5),\n",
        "  T.RandomHorizontalFlip(),\n",
        "  T.RandomVerticalFlip(),\n",
        "  T.ToTensor(),\n",
        "  normalize\n",
        "])\n",
        "transforms = T.Compose([\n",
        "  resize,\n",
        "  T.ToTensor(),\n",
        "  normalize\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GxTIbTj_mXxM",
        "outputId": "c9061191-ba63-482d-eb4e-a3498c1e5611"
      },
      "source": [
        "import torchvision.datasets as datasets\n",
        "\n",
        "train_ds = datasets.ImageFolder(path.join(data_dir, 'Training'),\n",
        "                                train_transforms)\n",
        "len(train_ds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "51658"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tAGsjjWgx24",
        "outputId": "67e182ca-4f4e-47bc-ae5b-9d140a98d38c"
      },
      "source": [
        "test_ds = datasets.ImageFolder(path.join(data_dir, 'Test'), transforms)\n",
        "len(test_ds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8617"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F961Gb0ZUmm3"
      },
      "source": [
        "## Create modular model \n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cd7xePlvUmm4"
      },
      "source": [
        "from torch.nn import Linear, Module\n",
        "import timm\n",
        "\n",
        "f_params = None\n",
        "\n",
        "class PretrainedModel(Module):\n",
        "    def __init__(self, model='rexnet'):\n",
        "        super().__init__()\n",
        "        model_name = self.get_model_name(model)\n",
        "        self.model = timm.create_model(\n",
        "            model_name, pretrained=True, num_classes=1)\n",
        "    \n",
        "    def get_model_name(self, general_model):\n",
        "        return 'rexnet_200' if general_model == 'rexnet' else \\\n",
        "               'tf_efficientnet_b8' if general_model == 'efficientnet' else ''\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x).squeeze(-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WEDynHWUmm5"
      },
      "source": [
        "## Defining the API\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyQ3D-5uUmm5"
      },
      "source": [
        "### Callbacks\n",
        "\n",
        "In this case the only Callback that will be used in every model will be an early stopping callback"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U38wxdqvuuan"
      },
      "source": [
        "from skorch.callbacks import EarlyStopping, Freezer, LRScheduler, ProgressBar\n",
        "from torch.optim.lr_scheduler import MultiplicativeLR, StepLR, LambdaLR\n",
        "\n",
        "is_not_trainable = lambda x: not x.startswith('model.fc') and \\\n",
        "                            not x.startswith('model._fc') and \\\n",
        "                            not x.startswith('model.head') and \\\n",
        "                            not x.startswith('model.classifier')\n",
        "freezer = Freezer(is_not_trainable) \n",
        "early_stopping = EarlyStopping(patience=3)\n",
        "progress_bar = ProgressBar()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-i4GgEHPHKp3"
      },
      "source": [
        "lr = 5e-4\n",
        "num_warmup_steps = 6\n",
        "num_training_steps = 6\n",
        "peak_lr = 8e-3\n",
        "\n",
        "def lr_lambda(epoch):\n",
        "    if epoch < num_warmup_steps:\n",
        "        return (epoch / num_warmup_steps) * (peak_lr / lr)\n",
        "    return max(\n",
        "        0.0,\n",
        "        (num_training_steps - epoch) / max(1, num_training_steps - num_warmup_steps)\n",
        "    )\n",
        "\n",
        "# lr_lambda = lambda epoch: min(2 * epoch / 10, 0.9)\n",
        "scheduler = LRScheduler(policy=MultiplicativeLR, lr_lambda=lr_lambda)\n",
        "# scheduler = LRScheduler(policy=StepLR, gamma=8.95e-1, step_size=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9b7Q8CkUmm8"
      },
      "source": [
        "### Classifier class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouQuUaZduCI8"
      },
      "source": [
        "from torch import float64\n",
        "from skorch.classifier import NeuralNetBinaryClassifier\n",
        "from skorch.utils import to_tensor, to_numpy\n",
        "import sklearn.metrics as sk_metrics \n",
        "import numpy as np\n",
        "\n",
        "class MyClassifier(NeuralNetBinaryClassifier):\n",
        "    def infer(self, x, **fit_params):\n",
        "        x = to_tensor(x, device=self.device)\n",
        "        if isinstance(x, dict):\n",
        "            x_dict = self._merge_x_and_fit_params(x, fit_params)\n",
        "            return self.module_(**x_dict).to(device=self.device, dtype=float64)\n",
        "        return self.module_(x, **fit_params).to(device=self.device, dtype=float64)\n",
        "\n",
        "    def train_step_single(self, Xi, yi, **fit_params):\n",
        "        self.module_.train()\n",
        "        y_pred = self.infer(Xi, **fit_params)\n",
        "        yi = yi.to(device=self.device, dtype=float64)\n",
        "        loss = self.get_loss(y_pred, yi, X=Xi, training=True)\n",
        "        loss.backward()\n",
        "        return { 'loss': loss, 'y_pred': y_pred }\n",
        "\n",
        "    def validation_step(self, Xi, yi, **fit_params):\n",
        "        self.module_.eval()\n",
        "        y_pred = self.infer(Xi, **fit_params)\n",
        "        yi = yi.to(device=self.device, dtype=float64)\n",
        "        loss = self.get_loss(y_pred, yi, X=Xi, training=False)\n",
        "        return { 'loss': loss,'y_pred': y_pred }\n",
        "\n",
        "    def _get_y_values(self, X):\n",
        "        y_true, y_pred = [], []\n",
        "        nonlinearity = self._get_predict_nonlinearity()\n",
        "        for images, labels in self.get_iterator(X):\n",
        "            images = images.to(self.device)\n",
        "            outputs = nonlinearity(self.module_(images))\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            y_true.append(to_numpy(labels))\n",
        "            y_pred.append(to_numpy(predicted))\n",
        "        y_true = np.concatenate(y_true)\n",
        "        y_pred = np.concatenate(y_pred)\n",
        "        return y_true, y_pred\n",
        "\n",
        "    def score(self, X):\n",
        "        y_true, y_pred = self._get_y_values(X)\n",
        "        return sk_metrics.roc_auc_score(y_true, y_pred)\n",
        "    \n",
        "    def scores(self, X):\n",
        "        y_true, y_pred = self._get_y_values(X)\n",
        "        accuracy = sk_metrics.accuracy_score(y_true, y_pred)\n",
        "        confusion_matrix = sk_metrics.confusion_matrix(y_true, y_pred)\n",
        "        f1 = sk_metrics.f1_score(y_true, y_pred)\n",
        "        auc = sk_metrics.roc_auc_score(y_true, y_pred)\n",
        "        return accuracy, confusion_matrix, f1, auc\n",
        "\n",
        "    def print_and_plot_scores(self, X):\n",
        "        accuracy, confusion_matrix, f1, auc = self.scores(X)\n",
        "        print(f'Accuracy: {accuracy}')\n",
        "        print(f'F1 Score: {f1}')\n",
        "        print(f'AUC: {auc}')\n",
        "        disp = sk_metrics.ConfusionMatrixDisplay(\n",
        "          confusion_matrix, display_labels=['Fire', 'No_Fire'])\n",
        "        disp.plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7Z5j-8ogntu"
      },
      "source": [
        "### Classifier helper functions\n",
        "\n",
        "The next code will be used to create helper functions to easily create, fit and evaluate different type of CNN architectures"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZj_giOyUmm8"
      },
      "source": [
        "from torch.optim import Adam\n",
        "from skorch.callbacks import Checkpoint\n",
        "from skorch.dataset import CVSplit\n",
        "from skorch.helper import predefined_split\n",
        "\n",
        "def create_model(module_model):\n",
        "    global f_params\n",
        "\n",
        "    f_params = path.join(drive_path, f'Models/best_{module_model}.pt')\n",
        "    checkpoint = Checkpoint(f_params=f_params, monitor='valid_acc_best')\n",
        "    callbacks = [checkpoint, freezer, scheduler]\n",
        "\n",
        "    return MyClassifier(\n",
        "        PretrainedModel,\n",
        "        module__model=module_model,\n",
        "        optimizer=Adam,\n",
        "        lr=lr,\n",
        "        batch_size=64,\n",
        "        max_epochs=15,\n",
        "        iterator_train__shuffle=True,\n",
        "        iterator_train__num_workers=16,\n",
        "        iterator_valid__shuffle=True,\n",
        "        iterator_valid__num_workers=16,\n",
        "        train_split=CVSplit(0.2, random_state=seed),\n",
        "        callbacks=callbacks,\n",
        "        device='cuda'\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1nEzDdmi0br"
      },
      "source": [
        "def create_and_fit(model_name):\n",
        "    net = create_model(model_name)\n",
        "    net.fit(train_ds, y=None)\n",
        "    net.load_params(f_params=f_params)\n",
        "    return net"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5llRfok5hhwZ"
      },
      "source": [
        "## Models results\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVSReHWzghMG"
      },
      "source": [
        "### Rexnet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dz11nA6CgZfB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f853063-0438-4512-abeb-56c8b9a5eaa8"
      },
      "source": [
        "rexnet = create_and_fit('rexnet')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  epoch    train_loss    valid_acc    valid_loss    cp      lr       dur\n",
            "-------  ------------  -----------  ------------  ----  ------  --------\n",
            "      1        \u001b[36m0.6338\u001b[0m       \u001b[32m0.6574\u001b[0m        \u001b[35m1.6776\u001b[0m     +  0.0005  334.9860\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "      2        \u001b[36m0.1727\u001b[0m       \u001b[32m0.6929\u001b[0m        \u001b[35m1.1489\u001b[0m     +  0.0027  338.9241\n",
            "      3        \u001b[36m0.0610\u001b[0m       \u001b[32m0.7809\u001b[0m        \u001b[35m1.0547\u001b[0m     +  0.0284  337.1139\n",
            "      4        \u001b[36m0.0450\u001b[0m       0.7203        1.2561        0.0284  338.2943\n",
            "      5        \u001b[36m0.0431\u001b[0m       0.7311        1.4398        0.0253  337.9582\n",
            "      6        \u001b[36m0.0401\u001b[0m       0.6529        2.0123        0.0197  337.3363\n",
            "      7        \u001b[36m0.0335\u001b[0m       0.6798        2.1060        0.0131  338.0526\n",
            "      8        \u001b[36m0.0333\u001b[0m       0.6863        1.7308        0.0073  341.2416\n",
            "      9        \u001b[36m0.0255\u001b[0m       0.6951        1.4303        0.0032  343.8477\n",
            "     10        \u001b[36m0.0218\u001b[0m       0.7011        1.3842        0.0011  338.7790\n",
            "     11        0.0259       0.7071        1.3625        0.0002  336.2726\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWXJJtTkGqtO"
      },
      "source": [
        "rexnet.print_and_plot_scores(test_ds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "McSBPhJshE_U"
      },
      "source": [
        "### EfficientNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFGkLLS_hpYy"
      },
      "source": [
        "efficientnet = create_and_fit('efficientnet')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQJdDUwGGuq3"
      },
      "source": [
        "efficientnet.print_and_plot_scores(test_ds)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}