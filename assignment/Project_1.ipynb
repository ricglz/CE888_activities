{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python [default]",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "name": "Project_1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ricglz/CE888_activities/blob/main/assignment/Project_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jR0i3ECTUmmx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "164a0adc-a3a2-45f0-be4a-8e743097dcd7"
      },
      "source": [
        "! pip install torch torchvision skorch efficientnet_pytorch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.7.0+cu101)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.8.1+cu101)\n",
            "Requirement already satisfied: skorch in /usr/local/lib/python3.6/dist-packages (0.9.0)\n",
            "Requirement already satisfied: efficientnet_pytorch in /usr/local/lib/python3.6/dist-packages (0.7.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch) (0.16.0)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch) (0.8)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch) (3.7.4.3)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (7.0.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from skorch) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from skorch) (0.22.2.post1)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.6/dist-packages (from skorch) (0.8.7)\n",
            "Requirement already satisfied: tqdm>=4.14.0 in /usr/local/lib/python3.6/dist-packages (from skorch) (4.41.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.19.1->skorch) (1.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bu0y8g8gUmmz"
      },
      "source": [
        "## Preparations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXhVa-RwUmmz"
      },
      "source": [
        "Before we begin, lets mount the google drive to later on read information from it:\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NeqA16HnUmmz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59d8ada0-88bd-4645-da0f-4ec9f5f24f10"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive_path = '/content/gdrive'\n",
        "drive.mount(drive_path, force_remount=False)\n",
        "drive_path += '/MyDrive'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iixFi55mUmm1"
      },
      "source": [
        "## The Problem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9sBrFemBUmm1"
      },
      "source": [
        "We are going to train a neural network to classify **ants** and **bees**. The dataset consist of 120 training images and 75 validiation images for each class. First we create the training and validiation datasets:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDmTwvy1Umm2"
      },
      "source": [
        "import torchvision.transforms as T\n",
        "import torchvision.datasets as datasets\n",
        "from os import path\n",
        "\n",
        "data_dir = path.join(drive_path, 'Flame')\n",
        "resize = T.Resize(254)\n",
        "normalize = T.Normalize([0.485, 0.456, 0.406], \n",
        "                         [0.229, 0.224, 0.225])\n",
        "train_transforms = T.Compose([\n",
        "  resize,\n",
        "  T.RandomHorizontalFlip(),\n",
        "  T.RandomVerticalFlip(),\n",
        "  T.ToTensor(),\n",
        "  normalize\n",
        "])\n",
        "transforms = T.Compose([\n",
        "  resize,\n",
        "  T.ToTensor(),\n",
        "  normalize\n",
        "])\n",
        "\n",
        "train_ds = datasets.ImageFolder(path.join(data_dir, 'Training'), transforms)\n",
        "test_ds = datasets.ImageFolder(path.join(data_dir, 'Test'), transforms)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N99nSb3GUmm2"
      },
      "source": [
        "The train dataset includes data augmentation techniques such as cropping to size 224 and horizontal flips.The train and validiation datasets are normalized with mean: `[0.485, 0.456, 0.406]`, and standard deviation: `[0.229, 0.224, 0.225]`. These values are the means and standard deviations of the ImageNet images. We used these values because the pretrained model was trained on ImageNet."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F961Gb0ZUmm3"
      },
      "source": [
        "## Loading pretrained model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mVpUMblUmm3"
      },
      "source": [
        "We use a pretrained `ResNet18` neural network model with its final layer replaced with a fully connected layer:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cd7xePlvUmm4"
      },
      "source": [
        "from torch import load, FloatTensor\n",
        "from torch.nn import Linear, Module\n",
        "from torchvision.models import resnext101_32x8d\n",
        "from efficientnet_pytorch import EfficientNet\n",
        "\n",
        "f_params = None\n",
        "\n",
        "class PretrainedModel(Module):\n",
        "    def __init__(self, model='resnext', use_pretrained=True):\n",
        "        super().__init__()\n",
        "        if model == 'resnext':\n",
        "            self.build_resnext_model(use_pretrained)\n",
        "        elif model == 'efficientnet':\n",
        "            self.build_efficientnet(use_pretrained)\n",
        "    \n",
        "    def get_state_dict(self):\n",
        "        remove_model_prefix = lambda string: string[6:]\n",
        "        return { remove_model_prefix(k): v for k, v in load(f_params).items() }\n",
        "\n",
        "    def build_resnext_model(self, use_pretrained):\n",
        "        self.model = resnext101_32x8d(pretrained=(not use_pretrained))\n",
        "        num_ftrs = self.model.fc.in_features\n",
        "        self.model.fc = Linear(num_ftrs, 1)\n",
        "        if use_pretrained:\n",
        "            self.model.load_state_dict(self.get_state_dict())\n",
        "    \n",
        "    def build_efficientnet(self, use_pretrained):\n",
        "        model_name = 'efficientnet-b7'\n",
        "        if use_pretrained:\n",
        "            self.model = EfficientNet.from_name(model_name, num_classes=1)\n",
        "            self.model.load_state_dict(self.get_state_dict())\n",
        "        else:\n",
        "            self.model = EfficientNet.from_pretrained(model_name, num_classes=1)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        return self.model(x).squeeze(-1).type(FloatTensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1t7R8UgSUmm4"
      },
      "source": [
        "Since we are training a binary classifier, the output of the final fully connected layer has size 2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WEDynHWUmm5"
      },
      "source": [
        "## Defining the API\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyQ3D-5uUmm5"
      },
      "source": [
        "### Callbacks\n",
        "\n",
        "In this case the only Callback that will be used in every model will be an early stopping callback"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U38wxdqvuuan"
      },
      "source": [
        "from skorch.callbacks import EarlyStopping\n",
        "\n",
        "early_stopping = EarlyStopping(patience=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9b7Q8CkUmm8"
      },
      "source": [
        "### Helper functions classifier\n",
        "\n",
        "The next code will be used to create helper functions to easily create, fit and evaluate different type of CNN architectures"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouQuUaZduCI8"
      },
      "source": [
        "from torch import float64\n",
        "from skorch.classifier import NeuralNetBinaryClassifier\n",
        "from skorch.utils import to_tensor\n",
        "\n",
        "class MyClassifier(NeuralNetBinaryClassifier):\n",
        "    def infer(self, x, **fit_params):\n",
        "        x = to_tensor(x, device=self.device)\n",
        "        if isinstance(x, dict):\n",
        "            x_dict = self._merge_x_and_fit_params(x, fit_params)\n",
        "            return self.module_(**x_dict).to(device=self.device, dtype=float64)\n",
        "        return self.module_(x, **fit_params).to(device=self.device, dtype=float64)\n",
        "\n",
        "    def train_step_single(self, Xi, yi, **fit_params):\n",
        "        self.module_.train()\n",
        "        y_pred = self.infer(Xi, **fit_params)\n",
        "        yi = yi.to(device=self.device, dtype=float64)\n",
        "        loss = self.get_loss(y_pred, yi, X=Xi, training=True)\n",
        "        loss.backward()\n",
        "        return { 'loss': loss,'y_pred': y_pred }\n",
        "\n",
        "    def validation_step(self, Xi, yi, **fit_params):\n",
        "        self.module_.eval()\n",
        "        y_pred = self.infer(Xi, **fit_params)\n",
        "        yi = yi.to(device=self.device, dtype=float64)\n",
        "        loss = self.get_loss(y_pred, yi, X=Xi, training=False)\n",
        "        return { 'loss': loss,'y_pred': y_pred }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZj_giOyUmm8"
      },
      "source": [
        "from torch.optim import Adam\n",
        "from skorch.callbacks import Checkpoint\n",
        "from skorch.dataset import CVSplit\n",
        "\n",
        "lr = 1e-2\n",
        "\n",
        "def create_model(module_mode):\n",
        "    global f_params\n",
        "\n",
        "    model_path = f'Models/best_{module_model}.pt'\n",
        "    f_params = path.join(drive_path, model_path)\n",
        "    checkpoint = Checkpoint(f_params=f_params, monitor='valid_acc_best')\n",
        "    net = MyClassifier(\n",
        "        PretrainedModel,\n",
        "        module__use_pretrained=False,\n",
        "        module__model=module_model,\n",
        "        optimizer=Adam,\n",
        "        lr=lr,\n",
        "        batch_size=8,\n",
        "        max_epochs=50,\n",
        "        iterator_train__shuffle=True,\n",
        "        iterator_train__num_workers=16,\n",
        "        iterator_valid__shuffle=True,\n",
        "        iterator_valid__num_workers=16,\n",
        "        train_split=CVSplit(0.2),\n",
        "        callbacks=[early_stopping, checkpoint],\n",
        "        device='cuda'\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFGbsKASgq3-"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "from skorch.utils import to_numpy\n",
        "\n",
        "def score(net, X, y=None):\n",
        "    y_true = y\n",
        "    if y_true is None:\n",
        "      ds = net.get_dataset(X) \n",
        "      target_iterator = net.get_iterator(ds, training=False) \n",
        "      y_true = np.concatenate([to_numpy(y) for _, y in target_iterator])\n",
        "\n",
        "    if y_true is None:\n",
        "      return 1\n",
        "\n",
        "    y_pred = net.predict(X)\n",
        "    if y_pred is None:\n",
        "      return 0\n",
        "    return accuracy_score(y_true, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1nEzDdmi0br"
      },
      "source": [
        "def create_fit_and_score(model_name):\n",
        "    net = create_model(model_name)\n",
        "    net.fit(train_ds, y=None)\n",
        "    score(net, test_ds, y=None)\n",
        "    return net"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "II7x55KXUmm9"
      },
      "source": [
        "That is quite a few parameters! Lets walk through each one:\n",
        "\n",
        "1. `model_ft`: Our `ResNet18` neural network\n",
        "2. `criterion=nn.CrossEntropyLoss`: loss function\n",
        "3. `lr`: Initial learning rate\n",
        "4. `batch_size`: Size of a batch\n",
        "5. `max_epochs`: Number of epochs to train\n",
        "6. `module__output_features`: Used by `__init__` in our `PretrainedModel` class to set the number of classes.\n",
        "7. `optimizer`: Our optimizer\n",
        "8. `optimizer__momentum`: The initial momentum\n",
        "9. `iterator_{train,valid}__{shuffle,num_workers}`: Parameters that are passed to the dataloader.\n",
        "10. `train_split`: A wrapper around `val_ds` to use our validation dataset.\n",
        "11. `callbacks`: Our callbacks \n",
        "12. `device`: Set to `cuda` to train on gpu.\n",
        "\n",
        "Now we are ready to train our neural network:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVSReHWzghMG"
      },
      "source": [
        "## Resnext model\n",
        "\n",
        "----"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dz11nA6CgZfB"
      },
      "source": [
        "net = create_fit_and_score('resnext')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "McSBPhJshE_U"
      },
      "source": [
        "## EfficientNet\n",
        "\n",
        "----"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFGkLLS_hpYy"
      },
      "source": [
        "net = create_fit_and_score('resnext')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}