{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "testing_best.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ricglz/CE888_activities/blob/main/assignment/testing_best.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgkVi8QRsbB0"
      },
      "source": [
        "!pip install -U -qqq torch==1.8.0 torchvision torchtext\n",
        "!pip install -qqq timm pytorch-lightning wandb\n",
        "!git clone https://github.com/ricglz/CE888_activities.git repo\n",
        "%cd repo/assignment/scripts/\n",
        "!python utils.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WuukCXSGyrdz"
      },
      "source": [
        "!wandb login <key>"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fsOxJxSyxbq"
      },
      "source": [
        "model_names = ('rexnet_200')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBqsL8oPyu2S"
      },
      "source": [
        "for model_name in model_names:\n",
        "    checkpoint_path=path.join('/content/gdrive/MyDrive/Models/Lightning',\n",
        "                              model_name,\n",
        "                              'best.ckpt')\n",
        "    !python test.py --model_name=model_name --precision=16 \\\n",
        "                    --checkpoint_path=checkpoint_path --lr=0 --tta=5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jL4exZ1WllnM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "332d9d33-9325-445a-95aa-4cbab5fd2ed0"
      },
      "source": [
        "!python train.py --anneal_strategy=cos --base_momentum=0.8051269571918493 --div_factor=7.439738529162385 --drop_rate=0.4068513486859972 --epochs=5 --final_div_factor=11916.417733845818 --lr=0.04056258042139802 --max_momentum=0.9269449782055802 --model_name=rexnet_200 --pct_start=0.4355520121605256 --precision=16 --stages=5 --three_phase=False --train_bn=False --unfreeze_per_step=18 --weight_decay=1.720985158960819e-05"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mricglz\u001b[0m (use `wandb login --relogin` to force relogin)\n",
            "2021-03-30 00:58:33.719848: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.23\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mpeach-smoke-603\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ricglz/repo-assignment_scripts\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ğŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ricglz/repo-assignment_scripts/runs/3j5tu6zv\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in /content/repo/assignment/scripts/wandb/run-20210330_005832-3j5tu6zv\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb offline` to turn off syncing.\n",
            "\n",
            "Global seed set to 42\n",
            "GPU available: True, used: True\n",
            "TPU available: None, using: 0 TPU cores\n",
            "Using native 16bit precision.\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name      | Type              | Params\n",
            "------------------------------------------------\n",
            "0 | base      | ReXNetV1          | 13.8 M\n",
            "1 | criterion | BCEWithLogitsLoss | 0     \n",
            "2 | metrics   | ModuleDict        | 0     \n",
            "------------------------------------------------\n",
            "2.6 K     Trainable params\n",
            "13.8 M    Non-trainable params\n",
            "13.8 M    Total params\n",
            "55.233    Total estimated model params size (MB)\n",
            "Epoch: 0 - Time: 4.49e+5h - loss: nan.0 - v_num: u6zv - val_loss: 10.80 - val_score: 0.000\n",
            "Start training\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:795: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "Epoch: 0 - Time: 2.310m - loss: 0.651 - v_num: u6zv - val_loss: 1.050 - val_score: 0.667 - train_loss: 0.947\n",
            "Epoch: 1 - Time: 2.440m - loss: 0.0528 - v_num: u6zv - val_loss: 1.270 - val_score: 0.689 - train_loss: 0.148\n",
            "Epoch: 2 - Time: 2.550m - loss: 0.0379 - v_num: u6zv - val_loss: 0.890 - val_score: 0.803 - train_loss: 0.00351\n",
            "Epoch: 3 - Time: 2.650m - loss: 0.0345 - v_num: u6zv - val_loss: 0.368 - val_score: 0.866 - train_loss: 0.000106\n",
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:52: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
            "  warnings.warn(*args, **kwargs)\n",
            "Total duration: 11.10m\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Start test\n",
            "Total duration: 19.70s\n",
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{'test_Accuracy': 0.8767425417900085,\n",
            " 'test_F1': 0.8556265830993652,\n",
            " 'test_loss': 0.36760205030441284,\n",
            " 'test_score': 0.8661845922470093}\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 889\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: /content/repo/assignment/scripts/wandb/run-20210330_005832-3j5tu6zv/logs/debug.log\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: /content/repo/assignment/scripts/wandb/run-20210330_005832-3j5tu6zv/logs/debug-internal.log\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                        train_loss 0.00024\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                             epoch 4\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                               trainer/global_step 4196\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                          _runtime 696\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                        _timestamp 1617066608\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                             _step 91\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                    train_Accuracy 0.98702\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                          train_F1 0.98704\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                          val_loss 0.3676\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                      val_Accuracy 0.87674\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                            val_F1 0.85563\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                         val_score 0.86618\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                         test_loss 0.3676\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                     test_Accuracy 0.87674\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                           test_F1 0.85563\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                        test_score 0.86618\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train_loss â–ˆâ–‡â–†â–„â–‚â–„â–…â–‚â–‚â–„â–‚â–â–‚â–â–â–‚â–ƒâ–â–â–â–â–â–â–‚â–â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                 epoch â–â–â–â–â–â–â–â–â–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–…â–…â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–†â–ˆâ–ˆâ–ˆâ–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   trainer/global_step â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        train_Accuracy â–â–‡â–ˆâ–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              train_F1 â–â–‡â–ˆâ–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              val_loss â–†â–ˆâ–…â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          val_Accuracy â–â–â–†â–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                val_F1 â–â–ƒâ–†â–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             val_score â–â–‚â–†â–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             test_loss â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         test_Accuracy â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               test_F1 â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            test_score â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mpeach-smoke-603\u001b[0m: \u001b[34mhttps://wandb.ai/ricglz/repo-assignment_scripts/runs/3j5tu6zv\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}