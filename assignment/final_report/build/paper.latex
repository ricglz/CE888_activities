%% This is a skeleton file demonstrating the use of IEEEtran.cls
%% (requires IEEEtran.cls version 1.8b or later) with an IEEE
%% Computer Society journal paper.
%%
%% Support sites:
%% http://www.michaelshell.org/tex/ieeetran/
%% http://www.ctan.org/pkg/ieeetran
%% and
%% http://www.ieee.org/

\documentclass[10pt,journal,compsoc]{IEEEtran}

% *** CITATION PACKAGES ***
\usepackage{cite}

% *** GRAPHICS RELATED PACKAGES ***
\usepackage{graphicx,subcaption}
\graphicspath{{./img}}
\DeclareGraphicsExtensions{.pdf,.jpeg,.png}

% *** ALIGNMENT PACKAGES ***
\usepackage{float, array}

% *** PDF, URL AND HYPERLINK PACKAGES ***
\usepackage[unicode=true,breaklinks,hidelinks]{hyperref}
\urlstyle{same}
\usepackage{csquotes}

% For tables
\usepackage{booktabs}

% For listing
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}

% Verbatim
\usepackage{listings}
\lstset{
  frame=single,
  language=Python,
  basicstyle=\small,
}

\makeatletter
\def\lst@makecaption{%
  \def\@captype{table}%
  \@makecaption
}
\makeatother

\makeatletter
\def\lst@makecaption{%
  \def\@captype{table}%
  \@makecaption
}
\makeatother

\begin{document}
%
% paper title
% Titles are generally capitalized except for words such as a, an, and, as,
% at, but, by, for, in, nor, of, on, or, the, to and up, which are usually
% not capitalized unless they are the first or last word of the title.
% Linebreaks \\ can be used within to get better formatting as desired.
% Do not put math or special symbols in the title.
\title{Improving Fire Detection with Efficient Training Techniques}

% author names and IEEE memberships
% note positions of commas and nonbreaking spaces ( ~ ) LaTeX will not break
% a structure at a ~ so this keeps an author's name from being broken across
% two lines.
% use \thanks{} to gain access to the first footnote area
% a separate \thanks must be used for each paragraph as LaTeX2e's \thanks
% was not built to handle multiple paragraphs

\author{Ricardo~Gonzalez, 2003297}

% The paper headers
% \markboth{Journal of \LaTeX\ Class Files,~Vol.~14, No.~8, August~2015}%
% {Shell \MakeLowercase{\textit{et al.}}: Bare Demo of IEEEtran.cls for Computer Society Journals}

% for Computer Society papers, we must declare the abstract and index terms
% PRIOR to the title within the \IEEEtitleabstractindextext IEEEtran
% command as these need to go into the title area created by \maketitle.
% As a general rule, do not put math, special symbols or citations
% in the abstract or keywords.
\IEEEtitleabstractindextext{%
\begin{abstract}
Pending abstract
\end{abstract}

% Note that keywords are not normally used for peerreview papers.
\begin{IEEEkeywords}
    CNN;
    Deep Learning;
    Image Classification\end{IEEEkeywords}}

% make the title area
\maketitle

% To allow for easy dual compilation without having to reenter the
% abstract/keywords data, the \IEEEtitleabstractindextext text will
% not be used in maketitle, but will appear (i.e., to be "transported")
% here as \IEEEdisplaynontitleabstractindextext when the compsoc
% or transmag modes are not selected <OR> if conference mode is selected
% - because all conference papers position the abstract like regular
% papers do.
\IEEEdisplaynontitleabstractindextext
% \IEEEdisplaynontitleabstractindextext has no effect when using
% compsoc or transmag under a non-conference mode.

% For peer review papers, you can put extra information on the cover
% page as needed:
% \ifCLASSOPTIONpeerreview
% \begin{center} \bfseries EDICS Category: 3-BBND \end{center}
% \fi
%
% For peerreview papers, this IEEEtran command inserts a page break and
% creates the second title. It will be ignored for other modes.
\IEEEpeerreviewmaketitle

\IEEEraisesectionheading{\section{Introduction}\label{introduction}}

\IEEEPARstart{N}{owadays} due to the advancements in AI and the
increasing amount of ecological disasters have led that many researchers
focused their attention in not only make new advancements in the theory
of the field, but also propose ways to solve, prevent or detect those
disasters to mitigate the impact that they have \cite{weber2020}.

A natural disaster is researched this way are Wildfires. According to
\cite{NOAA2020} wildfires produce emissions which are highly
contaminant, leading to an increase in air pollution not only in the
area affected by the wildfires, but also close areas near to it.
Furthermore, the natural fauna and flora are also threatened, by
consequence that the fire was caused due to human intervention. This is
explained by \cite{malhi2009}, who uses as an example the Amazon
Rainforest where the human caused wildfires alongside droughts have
threatened the Rainforest to reach a possible tipping point, where it
would become unsustainable unless there is some kind of intervention.

To be able to tackle this problem, researchers have decided to attempt
the detection of wildfires in their early stages having the examples of
\cite{shamsoshoara2020} and \cite{saied2020}, whose work have been
either proposing CNN models using their own datasets or creating a new
dataset containing images to create models that can be used to solve the
problem.

Nevertheless, the models normally are not very accurate, an example of
this is the one proposed by \cite{shamsoshoara2020} whose proposed model
achieved 76\%, which shows that is still possible and worth to achieve a
higher score, specially considering that the architecture used is
considered an old model, and new and better ones have been published
since then. In addition to the prior the training process was a very
simple training process that was primarily based on training through a
lot of epochs. Thus, new techniques can be used to not only increase the
accuracy but also reduce the amount of epochs needed to train it.

That is why the objective of this research is to propose using new
architectures, models that can achieve higher accuracy over the same
test dataset as the one used at \cite{shamsoshoara2020}, while needing
less amount of epochs to be trained.

\hypertarget{background-literature-review}{%
\section{Background / Literature
Review}\label{background-literature-review}}

\hypertarget{mixed-precision-training}{%
\subsection{Mixed-precision training}\label{mixed-precision-training}}

One of the current problems that people are facing nowadays with DL is
the amount of resources that it takes to train a model. Either because
the architecture has a lot of parameters and takes a lot of memory of
the GPU, or because it takes a lot of time to be trained due to the
computational power it needs. To solve this problem
\cite{micikevicius2018} proposed what is known as mixed-precision
training, where instead of use the full-precision number of 8 bytes, it
would use the 4 byte format. This led to a reduction of the amount of
memory it took to train the model, in addition to a speedup in the time
that the model took to be trained.

\hypertarget{data-augmentation}{%
\subsection{Data Augmentation}\label{data-augmentation}}

Data Augmentation is a technique that improves the generalization of the
network, this is done by performing manipulation of the data, being in
the case of images techniques such as: shearing, rotating, saturate and
others \cite{van2001}. This technique is effective because it generates
new data each time a new epoch is ran. Thus, resulting quite effective
when learning from an overall small dataset. In addition to the prior,
it also has been proven effective as it adds randomness to the training
as it reduces the changes that the same batch have the same data each
epoch \cite{perez2017}.

\hypertarget{autoaugment}{%
\subsubsection{AutoAugment}\label{autoaugment}}

Nevertheless, one limitation this technique has its effectiveness
depends on the augmentations done over the data and which will be its
correct parameters, mainly its magnitude and probability. A solution of
this limitation is proposed by \cite{cubuk2019} who created a procedure
called \emph{AutoAugment} that created a search space consisting of
policy which consisted of sub-policies that decide which augmentation to
do and which are its parameters. This resulted in an improvement of the
previous state-of-the-art models.

\hypertarget{test-time-augmentation}{%
\subsubsection{Test Time Augmentation}\label{test-time-augmentation}}

Even though, data augmentation is commonly used only for the training
phase it also has a purpose during the testing phase. This technique is
called Test Time Augmentation (TTA), in which the input is augmented and
passed as an input for the model n times to result in a total of n
outputs. With these outputs, then is performed a merge operation which
normally is to perform a mean between all the outputs obtained. This
merge result is then used to obtain the desired test metrics
\cite{kim2020}.

\hypertarget{mixup}{%
\subsection{Mixup}\label{mixup}}

\begin{figure}
\centering
\subcaptionbox{Before Mixup}{\includegraphics[width=0.2\textwidth]{img/before_mixup}}%
\hfill
\subcaptionbox{After Mixup}{\includegraphics[width=0.2\textwidth]{img/after_mixup}}%
\caption{Example of transformation of an image when using mixup}
\label{fig:mixup}
\end{figure}

Is a technique that was proposed by \cite{zhang2018} that was aimed to
help in the stabilization of adversarial networks in generative model,
nevertheless it has found success also in classification tasks. The
technique consists of mixing both the data and labels of elements in the
batch, resulting in an overall generalization of how it would look the
distribution of the data of two different elements of the same or
different class. An example of the result of mixup can be seen in figure
\ref{fig:mixup}.

\hypertarget{transfer-learning}{%
\subsection{Transfer learning}\label{transfer-learning}}

As said by \cite{torrey2010} ``Transfer learning is the improvement of
learning in a new task through the transfer of knowledge from a related
task that has already been learned''. This technique helps in reducing
the amount of computational time to achieve the same or better accuracy.
By using the weights of a model with the same architecture trained for
another task, the model will use that prior knowledge to learn this new
task faster, this has been proved by the examples of \cite{shao2018}

\hypertarget{onecyclelr}{%
\subsection{OneCycleLR}\label{onecyclelr}}

\begin{figure}
\centering
\includegraphics[width=0.5\textwidth,height=\textheight]{img/one_cycle_lr}
\caption{Behavior of the OneCycleLR}
\end{figure}

\hypertarget{methodology}{%
\section{Methodology}\label{methodology}}

\hypertarget{dataset}{%
\subsection{Dataset}\label{dataset}}

The dataset used was a merge between the datasets done by
\cite{Flame2020}, \cite{saied2020} and \cite{dunnings18}. The code to
perform the same preprocessing is fully available on Github
\footnote{\url{https://github.com/ricglz/CE888_activities/blob/main/assignment/scripts/data_preprocessing.py}}.

\hypertarget{flame-dataset}{%
\subsubsection{FLAME dataset}\label{flame-dataset}}

The FLAME dataset consists of 47,992 images that are labeled as having
fire or not. 39,375 of the total amount of images are for
training/validation. As can be seen at \ref{tab:1} the
training/validation set, the labels are skewed towards the class with
fire. These images were obtained by the researchers by extracting the
frames of videos recorded by drones of forest areas \cite{Flame2020}.

\begin{table}
\centering
\begin{tabular}{|l|c|c|r|}
\toprule
Dataset & Fire & No Fire & Total \\
\midrule
Train/Val & 25018 (63.54\%) & 14357 (36.46\%) & 39375 (100.00\%) \\
Test & 5137 (59.61\%) & 3480 (40.39\%) & 8617 (100.00\%) \\
\bottomrule
\end{tabular}
\caption{FLAME dataset distribution}
\label{tab:1}
\end{table}

\hypertarget{kaggles-dataset}{%
\subsubsection{Kaggle's dataset}\label{kaggles-dataset}}

This dataset was created for a NASA challenge in 2018, the authors
collected a total of 1,000 images all labeled for training data. These
images contrary to the previous dataset are from a wide range of
environments, from urban to rural areas. Nevertheless, the dataset is
skewed, containing 755 images labeled as fire and the rest as no-fire
\cite{saied2020}.

\hypertarget{dunnings-dataset}{%
\subsubsection{Dunning's dataset}\label{dunnings-dataset}}

The dataset was created by Dunning et al.~consisting of 23,408 images
for training. This dataset was created by merging other datasets and
material from public videos \cite{dunnings18}. This dataset also has a
skew over the fire images.

\hypertarget{merging-datasets}{%
\subsubsection{Merging datasets}\label{merging-datasets}}

All the images of the Kaggle's and Dunning's dataset were merged into
the training/validation dataset of flame.

\hypertarget{balancing-the-datasets}{%
\subsubsection{Balancing the datasets}\label{balancing-the-datasets}}

After merging the datasets, the next part of the preprocessing was to
balance the dataset. Because as mentioned in the prior sections all the
datasets are skewed towards the label with fire. To balance the dataset,
we over-sample the no fire class label by performing Data Augmentation
over random samples of the label. The augmentations done to the dataset
were brightness, contrast, rotation, horizontal and vertical flip. This
resulted in a dataset containing 76,726 images with a perfect balance
between the 2 classes.

\hypertarget{dividing-trainingvalidation}{%
\subsubsection{Dividing
Training/Validation}\label{dividing-trainingvalidation}}

The next step would be to split the training/validation dataset into its
own predefined folders, this would help for always using the same images
for training and validation, instead of random ones. Therefore the
dataset
\footnote{Dataset without halving training: \url{https://drive.google.com/file/d/1uv9vAl55IinuEMXHocnJQUhPbMikuSIX}}
was split into 80\% training and 20\% validation, will keeping the
balanced ratios between the labels.

\hypertarget{reducing-the-amount-of-data-in-training}{%
\subsubsection{Reducing the amount of data in
training}\label{reducing-the-amount-of-data-in-training}}

With a total of 61,378 images, there was a lot of data to process. If we
want that the training would be as efficient as possible it was a lot of
data to handle, in addition that most of images were very similar
between each other, as these were frames extracted of videos. Then it
was decided to cut the amount of training data into half, while keeping
the ratio of classes as before. This was the last step for the creation
of the dataset
\footnote{Dataset after halving training: \url{https://drive.google.com/file/d/1RrO4boe9jHUsCY1l9Z55iG1sfydJzubs/view}}
and resulted in a distribution as it shows in table \ref{tab:2}

\begin{table}
\centering
\begin{tabular}{|l|c|c|r|}
\toprule
Dataset & Fire & No Fire & Total \\
\midrule
Train & 15341 (50\%) & 15341 (50\%) & 30682 (100.00\%) \\
Validation & 7671 (50\%) & 7671 (50\%) & 15342 (100.00\%) \\
Test & 5137 (59.61\%) & 3480 (40.39\%) & 8617 (100.00\%) \\
\bottomrule
\end{tabular}
\caption{Dataset distribution after preprocessing}
\label{tab:2}
\end{table}

\hypertarget{model}{%
\subsection{Model}\label{model}}

For this paper we will experiment with different architectures as the
backbone of our model. Taking in consideration that
\cite{shamsoshoara2020} used the Xception \cite{chollet2017}
architecture as the backbone of their model, which could be considered
as an old architecture it is important to look for newer models which
are more efficient in terms of time of inference, training and amount of
parameters.

These conditions reduced the experimentation to the next architectures:
EfficientNet \cite{tan2020}, ReXNet \cite{han2020}, GENet \cite{lin2020}
and RepVGG \cite{ding2021}.

With these architectures we will perform transfer learning to be able to
learn from the current task. It must be mentioned that all of these
architectures have already been trained and have been shared by
\cite{timm2019} who have also shared the code to be able to used the
models.

\hypertarget{training}{%
\subsection{Training}\label{training}}

The model will be trained using Mixed Precision, in addition of using as
learning scheduler the OneCycleLR. Also we used a special data loader
which will create batches containing the same amount of random elements
of each class. This was possible due to the previous work of
\cite{galato2019}, who developed a similar sampler for their use case.

\hypertarget{tuning}{%
\subsection{Tuning}\label{tuning}}

\hypertarget{results}{%
\section{Results}\label{results}}

\hypertarget{conclusion}{%
\section{Conclusion}\label{conclusion}}

% can use a bibliography generated by BibTeX as a .bbl file
% BibTeX documentation can be easily obtained at:
% http://mirror.ctan.org/biblio/bibtex/contrib/doc/
% The IEEEtran BibTeX style support page is at:
% http://www.michaelshell.org/tex/ieeetran/bibtex/
%\bibliographystyle{IEEEtran}
% argument is your BibTeX string definitions and bibliography database(s)
%\bibliography{IEEEabrv,../bib/paper}
%
% <OR> manually copy in the resultant .bbl file
% set second argument of \begin to the number of references
% (used to reserve space for the reference number labels box)
\bibliographystyle{IEEEtran}
\bibliography{bibliography}
\end{document}
