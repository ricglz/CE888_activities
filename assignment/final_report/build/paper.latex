%% This is a skeleton file demonstrating the use of IEEEtran.cls
%% (requires IEEEtran.cls version 1.8b or later) with an IEEE
%% Computer Society journal paper.
%%
%% Support sites:
%% http://www.michaelshell.org/tex/ieeetran/
%% http://www.ctan.org/pkg/ieeetran
%% and
%% http://www.ieee.org/

\documentclass[10pt,journal,compsoc]{IEEEtran}

% *** CITATION PACKAGES ***
%
% normal IEEE
\usepackage[style=ieee]{biblatex}
\addbibresource{./bibliography.bib}

% *** GRAPHICS RELATED PACKAGES ***
%
\usepackage{graphicx,caption}

% *** MATH PACKAGES ***
% \usepackage{amsmath}

% *** ALIGNMENT PACKAGES ***
%
\usepackage{float}
\usepackage{array}

% *** SUBFIGURE PACKAGES ***
\usepackage[caption=false,font=footnotesize]{subfig}
% The latest version and documentation of subfig.sty can be obtained at:
% http://www.ctan.org/pkg/subfig

% *** PDF, URL AND HYPERLINK PACKAGES ***
%
\usepackage[unicode=true,breaklinks]{hyperref}
\urlstyle{same}

\usepackage{csquotes}

% For tables
\usepackage{booktabs}

% For listing
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}

% Verbatim
\usepackage{listings}
\lstset{
  frame=single,
  language=Python,
  basicstyle=\small,
}

\makeatletter
\def\lst@makecaption{%
  \def\@captype{table}%
  \@makecaption
}
\makeatother

\makeatletter
\def\lst@makecaption{%
  \def\@captype{table}%
  \@makecaption
}
\makeatother

\begin{document}
%
% paper title
% Titles are generally capitalized except for words such as a, an, and, as,
% at, but, by, for, in, nor, of, on, or, the, to and up, which are usually
% not capitalized unless they are the first or last word of the title.
% Linebreaks \\ can be used within to get better formatting as desired.
% Do not put math or special symbols in the title.
\title{Improving Fire Detection with Efficient Training Techniques}

% author names and IEEE memberships
% note positions of commas and nonbreaking spaces ( ~ ) LaTeX will not break
% a structure at a ~ so this keeps an author's name from being broken across
% two lines.
% use \thanks{} to gain access to the first footnote area
% a separate \thanks must be used for each paragraph as LaTeX2e's \thanks
% was not built to handle multiple paragraphs

\author{Ricardo~Gonzalez, 2003297}

% The paper headers
\markboth{Journal of \LaTeX\ Class Files,~Vol.~14, No.~8, August~2015}%
{Shell \MakeLowercase{\textit{et al.}}: Bare Demo of IEEEtran.cls for Computer Society Journals}

% for Computer Society papers, we must declare the abstract and index terms
% PRIOR to the title within the \IEEEtitleabstractindextext IEEEtran
% command as these need to go into the title area created by \maketitle.
% As a general rule, do not put math, special symbols or citations
% in the abstract or keywords.
\IEEEtitleabstractindextext{%
\begin{abstract}
Pending abstract
\end{abstract}

% Note that keywords are not normally used for peerreview papers.
\begin{IEEEkeywords}
    CNN;
    Deep Learning;
    Image Classification\end{IEEEkeywords}}

% make the title area
\maketitle

% To allow for easy dual compilation without having to reenter the
% abstract/keywords data, the \IEEEtitleabstractindextext text will
% not be used in maketitle, but will appear (i.e., to be "transported")
% here as \IEEEdisplaynontitleabstractindextext when the compsoc
% or transmag modes are not selected <OR> if conference mode is selected
% - because all conference papers position the abstract like regular
% papers do.
\IEEEdisplaynontitleabstractindextext
% \IEEEdisplaynontitleabstractindextext has no effect when using
% compsoc or transmag under a non-conference mode.

% For peer review papers, you can put extra information on the cover
% page as needed:
% \ifCLASSOPTIONpeerreview
% \begin{center} \bfseries EDICS Category: 3-BBND \end{center}
% \fi
%
% For peerreview papers, this IEEEtran command inserts a page break and
% creates the second title. It will be ignored for other modes.
\IEEEpeerreviewmaketitle

\IEEEraisesectionheading{\section{Introduction}\label{introduction}}

\IEEEPARstart{N}{owadays} due to the advancements in AI and the
increasing amount of ecological disasters have led that many researchers
focused their attention in not only make new advancements in the theory
of the field, but also propose ways to solve, prevent or detect those
disasters to mitigate the impact that they have \cite{weber2020}.

A natural disaster is researched this way are Wildfires. According to
\cite{NOAA2020} wildfires produce emissions which are highly
contaminant, leading to an increase in air pollution not only in the
area affected by the wildfires, but also close areas near to it.
Furthermore, the natural fauna and flora are also threatened, by
consequence that the fire was caused due to human intervention. This is
explained by \cite{malhi2009}, who uses as an example the Amazon
Rainforest where the human caused wildfires alongside droughts have
threatened the Rainforest to reach a possible tipping point, where it
would become unsustainable unless there is some kind of intervention.

To be able to tackle this problem, researchers have decided to attempt
the detection of wildfires in their early stages having the examples of
\cite{shamsoshoara2020} and \cite{saied2020}, whose work have been
either proposing CNN models using their own datasets or creating a new
dataset containing images to create models that can be used to solve the
problem.

Nevertheless, the models normally are not very accurate, an example of
this is the one proposed by \cite{shamsoshoara2020} whose proposed model
achieved 76\%, which shows that is still possible and worth to achieve a
higher score, specially considering that the architecture used is
considered an old model, and new and better ones have been published
since then. In addition to the prior the training process was a very
simple training process that was primarily based on training through a
lot of epochs. Thus, new techniques can be used to not only increase the
accuracy but also reduce the amount of epochs needed to train it.

That is why the objective of this research is to propose using new
architectures, models that can achieve higher accuracy over the same
test dataset as the one used at \cite{shamsoshoara2020}, while needing
less amount of epochs to be trained.

\hypertarget{background-literature-review}{%
\section{Background / Literature
Review}\label{background-literature-review}}

\hypertarget{data-augmentation}{%
\section{Data Augmentation}\label{data-augmentation}}

Data Augmentation is a technique that improves the generalization of the
network, this is done by performing manipulation of the data, being in
the case of images techniques such as: shearing, rotating, saturate and
others \cite{van2001}. This technique is effective because it generates
new data each time a new epoch is ran. Thus, resulting quite effective
when learning from an overall small dataset. In addition to the prior,
it also has been proven effective as it adds randomness to the training
as it reduces the changes that the same batch have the same data each
epoch \cite{perez2017}.

\hypertarget{autoaugment}{%
\subsection{AutoAugment}\label{autoaugment}}

Nevertheless, one limitation this technique has its effectiveness
depends on the augmentations done over the data and which will be its
correct parameters, mainly its magnitude and probability. A solution of
this limitation is proposed by \textcite{cubuk2019} who created a
procedure called \emph{AutoAugment} that created a search space
consisting of policy which consisted of sub-policies that decide which
augmentation to do and which are its parameters. This resulted in an
improvement of the previous state-of-the-art models.

\hypertarget{test-time-augmentation}{%
\subsection{Test Time Augmentation}\label{test-time-augmentation}}

Even though, data augmentation is commonly used only for the training
phase it also has a purpose during the testing phase. This technique is
called Test Time Augmentation (TTA), in which the input is augmented and
passed as an input for the model n times to result in a total of n
outputs. With these outputs, then is performed a merge operation which
normally is to perform a mean between all the outputs obtained. This
merge result is then used to obtain the desired test metrics
\cite{kim2020}

\hypertarget{mixed-precision-training}{%
\section{Mixed-precision training}\label{mixed-precision-training}}

One of the current problems that people are facing nowadays with DL is
the amount of resources that it takes to train a model. Either because
the architecture has a lot of parameters and takes a lot of memory of
the GPU, or because it takes a lot of time to be trained due to the
computational power it needs. To solve this problem
\textcite{micikevicius2018} proposed what is known as mixed-precision
training, where instead of use the full-precision number of 8 bytes, it
would use the 4 byte format. This led to a reduction of the amount of
memory it took to train the model, in addition to a speedup in the time
that the model took to be trained.

\hypertarget{mixup}{%
\section{Mixup}\label{mixup}}

Is a technique that was proposed by \textcite{zhang2018} that was aimed
to help in the stabilization of adversarial networks in generative
model, nevertheless it has found success also in classification tasks.
The technique consists of mixing both the data and labels of elements in
the batch, resulting in an overall generalization of how it would look
the distribution of the data of two different elements of the same or
different class. An example of the result of mixup can be seen in
\ref{fig:mixup}.

\hypertarget{methods}{%
\section{Methods}\label{methods}}

\hypertarget{results}{%
\section{Results}\label{results}}

\hypertarget{conclusion}{%
\section{Conclusion}\label{conclusion}}

% can use a bibliography generated by BibTeX as a .bbl file
% BibTeX documentation can be easily obtained at:
% http://mirror.ctan.org/biblio/bibtex/contrib/doc/
% The IEEEtran BibTeX style support page is at:
% http://www.michaelshell.org/tex/ieeetran/bibtex/
%\bibliographystyle{IEEEtran}
% argument is your BibTeX string definitions and bibliography database(s)
%\bibliography{IEEEabrv,../bib/paper}
%
% <OR> manually copy in the resultant .bbl file
% set second argument of \begin to the number of references
% (used to reserve space for the reference number labels box)
\printbibliography{References}
\end{document}
