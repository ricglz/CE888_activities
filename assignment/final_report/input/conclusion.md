# Conclusion

<!-- Summarize your key findings. Include important conclusions that can be drawn and further implications for the field. Discuss the benefits or shortcomings of your work and suggest future areas for research. -->

This paper developed four models that showed the necessity that exists of using efficient techniques and architectures to not only obtain a good model performance, while using less resources during the training. This allows researchers or other developers to implement these models in IoT devices, as the response will be faster than with models that demand more resources to operate. It could even allow the developers to add the software directly to the devices themselves, because based on the information in table \ref{tab:time} we can assume that the inference time of most of the models, with the exception of EfficientNet, is faster than needed.

Nevertheless, there are still factors that could improve the performance of the models, starting with having a more diverse dataset. As we consider that one problem with the datasets is the repetition of the same frames, caused due to being extracted from videos. This procedure may cause that the model can't learn to generalize quickly enough to classify one label with the other, or maybe every if the dataset is of very poor quality. In addition that basically this create the illusion that our dataset may be big enough, able to generalize the information, while the reality may be that there are not enough samples of all the environments.

Now that we know that these techniques help in the creation of better models, a next step could be to replicate the procedure, we should replicate the procedure for architectures that were designed for mobile devices or those devices with limited resources. Architectures such as: MobileNet \cite{howard2019}, FBNet \cite{wu2019} and pruned versions of the less complex versions of EfficientNet \cite{tan2020}.
