{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ricglz/CE888_activities/blob/main/assignment/Data_augmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jR0i3ECTUmmx",
    "outputId": "af59c450-7d08-4178-bbfe-4d02da6cdeec"
   },
   "outputs": [],
   "source": [
    "! [ ! -z \"$COLAB_GPU\" ] && pip install torch torchvision kaggleDownloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bu0y8g8gUmmz"
   },
   "source": [
    "# Preparations\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "S9lcSzI7KZrT"
   },
   "outputs": [],
   "source": [
    "from os import path, remove\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.utils as t_utils\n",
    "import torchvision.transforms as T\n",
    "\n",
    "try:\n",
    "    from kaggleDownloader import get_dataset\n",
    "    from google.colab import drive\n",
    "    in_colab = True\n",
    "except ImportError:\n",
    "    in_colab = False\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_path():\n",
    "    if in_colab:\n",
    "        drive_path = '/content/gdrive'\n",
    "        drive.mount(drive_path, force_remount=False)\n",
    "        return path.join(drive_path, 'MyDrive/Essex/Datasets/Flame/Training')\n",
    "    return './Flame/Training'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "oZoa1eTeKDUk"
   },
   "outputs": [],
   "source": [
    "classes = ['Fire', 'No_Fire']\n",
    "training_path = get_training_path()\n",
    "resize = T.Resize((224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "WVsJTO7bKdhD"
   },
   "outputs": [],
   "source": [
    "def save_image(img, label, index, prefix):\n",
    "    klass = classes[label]\n",
    "    img_path = path.join(training_path, f'{klass}/{prefix}_{index}.png')\n",
    "    t_utils.save_image(img, img_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resize images to the desired size\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 76706/76706 [34:13<00:00, 37.35it/s]  \n"
     ]
    }
   ],
   "source": [
    "train_ds = ImageFolder(training_path, T.Compose([resize, T.ToTensor()]))\n",
    "\n",
    "for index, (img_path, _) in enumerate(tqdm(train_ds.imgs)):\n",
    "    img, _ = train_ds[index]\n",
    "    t_utils.save_image(img, img_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lMnujpMEwJb1"
   },
   "source": [
    "# Add new dataset to the existent one\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YheqSr9ZXphW"
   },
   "source": [
    "One of the principal problems of the current dataset is that the images are basically a burst of shots of the same environment, this leads to the problem that the model learns to recognize the environment instead of recognizing fire\n",
    "\n",
    "To avoid this we will use another [dataset that can be found in kaggle](https://www.kaggle.com/phylake1337/fire-dataset). Which may help the model to actually recognize the fire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_kaggle_dataset():\n",
    "    get_dataset('kaggle datasets download -d phylake1337/fire-dataset')\n",
    "    transforms = T.Compose([resize, T.ToTensor()])\n",
    "    extra_data = ImageFolder('/content/fire_dataset', transforms)\n",
    "    for index, (img, label) in enumerate(tqdm(extra_data)):\n",
    "        save_image(img, label, index, 'extra_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_kaggle_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0M_WtMdFX6B-"
   },
   "source": [
    "# Balance datasets\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_balanced():\n",
    "    balance_imgs = glob(\n",
    "        f'{training_path}/**/balance*.png', recursive=True)\n",
    "    for balance_img in tqdm(balance_imgs):\n",
    "        remove(balance_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_balanced()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_minor_klass(train_ds):\n",
    "    targets = np.array(train_ds.targets)\n",
    "    fire_data_count = np.count_nonzero(targets == 0)\n",
    "    non_fire_data_count = np.count_nonzero(targets == 1)\n",
    "    klass_counts = [fire_data_count, non_fire_data_count]\n",
    "    minor_klass = np.argmin(klass_counts)\n",
    "    minor_count, max_count = min(klass_counts), max(klass_counts)\n",
    "    images_to_save = min(max_count - minor_count, minor_count)\n",
    "    return minor_klass, images_to_save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_dataset():\n",
    "    transforms = T.Compose([\n",
    "      resize,\n",
    "      T.ColorJitter(brightness=0.25, contrast=0.25),\n",
    "      T.RandomRotation(degrees=5),\n",
    "      T.RandomHorizontalFlip(),\n",
    "      T.RandomVerticalFlip(),\n",
    "      T.ToTensor(),\n",
    "    ])\n",
    "    train_ds = ImageFolder(training_path, transforms)\n",
    "    minor_klass, images_to_save = get_minor_klass(train_ds)\n",
    "    indexes_to_enhace = np.where(train_ds.targets == minor_klass)[0]\n",
    "    assert train_ds.targets[indexes_to_enhace[0]] == minor_klass\n",
    "    indexes_to_enhace = np.random.choice(indexes_to_enhace, images_to_save, replace=False)\n",
    "    assert len(indexes_to_enhace) == images_to_save\n",
    "    for save_img_index, index in enumerate(tqdm(indexes_to_enhace)):\n",
    "        img, label = train_ds[index]\n",
    "        save_image(img, label, save_img_index, 'balance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balance_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reduce the amount of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def half_the_data():\n",
    "    transforms = T.Compose([resize, T.ToTensor()])\n",
    "    train_ds = ImageFolder(training_path, transforms)\n",
    "    files = list(map(lambda a: a[0], train_ds.samples))\n",
    "    _, erase_files = train_test_split(\n",
    "        files, test_size=0.5, shuffle=True, stratify=train_ds.targets)\n",
    "    for file_to_erase in tqdm(erase_files):\n",
    "        remove(file_to_erase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38353/38353 [00:09<00:00, 4159.54it/s]\n"
     ]
    }
   ],
   "source": [
    "half_the_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g7HlqOPiZclm"
   },
   "source": [
    "# Check final count\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "_94a2RTF06U2"
   },
   "outputs": [],
   "source": [
    "train_ds = ImageFolder(training_path)\n",
    "targets = np.array(train_ds.targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "SO8t3J7S090e",
    "outputId": "d972c61e-4cfd-427e-a252-7a1305aeab7b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Fire data: 19176'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fire_data_count = np.count_nonzero(targets == 0)\n",
    "f'Fire data: {fire_data_count}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 431
    },
    "id": "BJjD8cQ-1DVc",
    "outputId": "af9ffa66-ae16-4545-e818-50c08fccd1bf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Non-Fire data: 19177'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_fire_data_count = np.count_nonzero(targets == 1)\n",
    "f'Non-Fire data: {non_fire_data_count}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "YfKG3al1Zf3Y",
    "outputId": "4a228e55-039a-46a0-8c7c-3d3d1b5165f6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Total: 38353'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'Total: {fire_data_count + non_fire_data_count}'"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Data_augmentation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
