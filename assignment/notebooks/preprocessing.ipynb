{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ricglz/CE888_activities/blob/main/assignment/Data_augmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jR0i3ECTUmmx",
    "outputId": "af59c450-7d08-4178-bbfe-4d02da6cdeec"
   },
   "outputs": [],
   "source": [
    "! [ ! -z \"$COLAB_GPU\" ] && pip install torch torchvision kaggleDownloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bu0y8g8gUmmz"
   },
   "source": [
    "# Preparations\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S9lcSzI7KZrT"
   },
   "outputs": [],
   "source": [
    "from os import path, mkdir, remove\n",
    "from shutil import move\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import Subset\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.utils as t_utils\n",
    "import torchvision.transforms as T\n",
    "\n",
    "try:\n",
    "    from kaggleDownloader import get_dataset\n",
    "    from google.colab import drive\n",
    "    in_colab = True\n",
    "except ImportError:\n",
    "    in_colab = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if in_colab:\n",
    "    drive_path = '/content/gdrive'\n",
    "    drive.mount(drive_path, force_remount=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'MyDrive/Essex/Datasets/Flame' if in_colab else './Flame'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oZoa1eTeKDUk"
   },
   "outputs": [],
   "source": [
    "classes = ['Fire', 'No_Fire']\n",
    "training_path = path.join(data_path, 'Training')\n",
    "test_path = path.join(data_path, 'Test')\n",
    "resize = T.Resize((224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WVsJTO7bKdhD"
   },
   "outputs": [],
   "source": [
    "def save_image(img, label, index, prefix):\n",
    "    klass = classes[label]\n",
    "    img_path = path.join(training_path, f'{klass}/{prefix}_{index}.png')\n",
    "    t_utils.save_image(img, img_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resize images to the desired size\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_dataset(ds_path):\n",
    "    ds = ImageFolder(ds_path, T.Compose([resize, T.ToTensor()]))\n",
    "    for index, (img_path, _) in enumerate(tqdm(ds.imgs)):\n",
    "        t_utils.save_image(ds[index][0], img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_dataset(training_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_dataset(test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lMnujpMEwJb1"
   },
   "source": [
    "# Add new dataset to the existent one\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YheqSr9ZXphW"
   },
   "source": [
    "One of the principal problems of the current dataset is that the images are basically a burst of shots of the same environment, this leads to the problem that the model learns to recognize the environment instead of recognizing fire\n",
    "\n",
    "To avoid this we will use another [dataset that can be found in kaggle](https://www.kaggle.com/phylake1337/fire-dataset). Which may help the model to actually recognize the fire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_kaggle_dataset():\n",
    "    get_dataset('kaggle datasets download -d phylake1337/fire-dataset')\n",
    "    transforms = T.Compose([resize, T.ToTensor()])\n",
    "    extra_data = ImageFolder('/content/fire_dataset', transforms)\n",
    "    for index, (img, label) in enumerate(tqdm(extra_data)):\n",
    "        save_image(img, label, index, 'extra_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_kaggle_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0M_WtMdFX6B-"
   },
   "source": [
    "# Balance datasets\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_balanced():\n",
    "    balance_imgs = glob(\n",
    "        f'{training_path}/**/balance*.png', recursive=True)\n",
    "    for balance_img in tqdm(balance_imgs):\n",
    "        remove(balance_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_balanced()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_minor_klass(train_ds):\n",
    "    targets = np.array(train_ds.targets)\n",
    "    fire_data_count = np.count_nonzero(targets == 0)\n",
    "    non_fire_data_count = np.count_nonzero(targets == 1)\n",
    "    klass_counts = [fire_data_count, non_fire_data_count]\n",
    "    minor_klass = np.argmin(klass_counts)\n",
    "    minor_count, max_count = min(klass_counts), max(klass_counts)\n",
    "    images_to_save = min(max_count - minor_count, minor_count)\n",
    "    return minor_klass, images_to_save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_dataset():\n",
    "    transforms = T.Compose([\n",
    "      resize,\n",
    "      T.ColorJitter(brightness=0.25, contrast=0.25),\n",
    "      T.RandomRotation(degrees=5),\n",
    "      T.RandomHorizontalFlip(),\n",
    "      T.RandomVerticalFlip(),\n",
    "      T.ToTensor(),\n",
    "    ])\n",
    "    train_ds = ImageFolder(training_path, transforms)\n",
    "    minor_klass, images_to_save = get_minor_klass(train_ds)\n",
    "    indexes_to_enhace = np.where(train_ds.targets == minor_klass)[0]\n",
    "    assert train_ds.targets[indexes_to_enhace[0]] == minor_klass\n",
    "    indexes_to_enhace = np.random.choice(indexes_to_enhace, images_to_save, replace=False)\n",
    "    assert len(indexes_to_enhace) == images_to_save\n",
    "    for save_img_index, index in enumerate(tqdm(indexes_to_enhace)):\n",
    "        img, label = train_ds[index]\n",
    "        save_image(img, label, save_img_index, 'balance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balance_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reduce the amount of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def half_the_data():\n",
    "    transforms = T.Compose([resize, T.ToTensor()])\n",
    "    train_ds = ImageFolder(training_path, transforms)\n",
    "    files = list(map(lambda a: a[0], train_ds.samples))\n",
    "    _, erase_files = train_test_split(\n",
    "        files, test_size=0.5, shuffle=True, stratify=train_ds.targets)\n",
    "    for file_to_erase in tqdm(erase_files):\n",
    "        remove(file_to_erase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "half_the_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_path = path.join(data_path, 'Validation')\n",
    "if not path.exists(validation_path):\n",
    "    mkdir(validation_path)\n",
    "    for klass in classes:\n",
    "        mkdir(path.join(validation_path, klass))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_training_dataset():\n",
    "    train_ds = ImageFolder(training_path)\n",
    "    targets = train_ds.targets\n",
    "    _, valid_idx= train_test_split(\n",
    "        np.arange(len(targets)), test_size=0.2,\n",
    "        shuffle=True, stratify=targets)\n",
    "    for idx in tqdm(valid_idx):\n",
    "        img_path, label = train_ds.imgs[idx]\n",
    "        filename = Path(img_path).name\n",
    "        klass = classes[label]\n",
    "        new_path = path.join(validation_path, klass, filename)\n",
    "        move(img_path, new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_training_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g7HlqOPiZclm"
   },
   "source": [
    "# Check final count\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_94a2RTF06U2"
   },
   "outputs": [],
   "source": [
    "train_ds = ImageFolder(training_path)\n",
    "targets = np.array(train_ds.targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "SO8t3J7S090e",
    "outputId": "d972c61e-4cfd-427e-a252-7a1305aeab7b"
   },
   "outputs": [],
   "source": [
    "fire_data_count = np.count_nonzero(targets == 0)\n",
    "f'Fire data: {fire_data_count}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 431
    },
    "id": "BJjD8cQ-1DVc",
    "outputId": "af9ffa66-ae16-4545-e818-50c08fccd1bf"
   },
   "outputs": [],
   "source": [
    "non_fire_data_count = np.count_nonzero(targets == 1)\n",
    "f'Non-Fire data: {non_fire_data_count}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "YfKG3al1Zf3Y",
    "outputId": "4a228e55-039a-46a0-8c7c-3d3d1b5165f6"
   },
   "outputs": [],
   "source": [
    "f'Total: {fire_data_count + non_fire_data_count}'"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Data_augmentation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
