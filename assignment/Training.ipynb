{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Training.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "mUUtCI6-nJH5",
        "IKioRsqnkdCH",
        "Bu0y8g8gUmmz",
        "3XqUaGeNebYT",
        "iixFi55mUmm1",
        "81IxA3OC0PsK",
        "VPM2UAiV0cpL",
        "F961Gb0ZUmm3",
        "mCJL6DnTCrwK",
        "7UW7W-u0PXYy",
        "Kh9nEppHc2BG",
        "vCOLnxQePb1b",
        "i2t8iJ38PRaE",
        "2kEzlvDeNF3q",
        "bCeMVuy-A4Ri",
        "5llRfok5hhwZ"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python [default]",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c7094d4c3994435abc4ff162b0a11b28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_85747c1886ce436a8050a9734eaa5ad3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_74636bca876f4c18b737ddccb0872d09",
              "IPY_MODEL_1a5661e09c394af9a881778b25107266"
            ]
          }
        },
        "85747c1886ce436a8050a9734eaa5ad3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "74636bca876f4c18b737ddccb0872d09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_43e1bb7ccd1541e9a120ea2de10e411e",
            "_dom_classes": [],
            "description": "Finding best initial lr: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 400,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 400,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d398a8470fc242f4aafc5bd10ed2a393"
          }
        },
        "1a5661e09c394af9a881778b25107266": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_16116875252e41d3878332fc1cf48ce3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 400/400 [01:49&lt;00:00,  3.69it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8d46f3de582a46d2ae89ad9637d74435"
          }
        },
        "43e1bb7ccd1541e9a120ea2de10e411e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d398a8470fc242f4aafc5bd10ed2a393": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "16116875252e41d3878332fc1cf48ce3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8d46f3de582a46d2ae89ad9637d74435": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ricglz/CE888_activities/blob/version_2/assignment/Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUUtCI6-nJH5"
      },
      "source": [
        "# Normally constant aspects (doesn't require as much config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKioRsqnkdCH"
      },
      "source": [
        "## Install dependencies\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jR0i3ECTUmmx"
      },
      "source": [
        "!pip --quiet install torch torchvision patool timm pytorch-lightning"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lfg7Kyt4i7Av"
      },
      "source": [
        "from math import ceil\n",
        "from os import path, mkdir\n",
        "from pandas import DataFrame\n",
        "from patoolib import extract_archive\n",
        "from sklearn.model_selection import train_test_split\n",
        "from time import time\n",
        "from tqdm import tqdm\n",
        "from zipfile import ZipFile\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import seaborn as sns\n",
        "import sys\n",
        "import timm\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "import pytorch_lightning.callbacks as pl_callbacks\n",
        "from pytorch_lightning.utilities import xla_device\n",
        "from pytorch_lightning.loggers import TensorBoardLogger\n",
        "from pytorch_lightning.metrics import Accuracy, ConfusionMatrix, \\\n",
        "                                      MetricCollection, F1\n",
        "\n",
        "from torch import cuda, sigmoid, stack, use_deterministic_algorithms\n",
        "from torch.nn import BCEWithLogitsLoss, ModuleDict\n",
        "from torch.nn.modules.batchnorm import _BatchNorm\n",
        "from torch.optim import Adam, AdamW, RMSprop, SGD\n",
        "from torch.optim.lr_scheduler import OneCycleLR\n",
        "from torch.utils.data import DataLoader, Dataset, Subset, random_split\n",
        "from torch.utils.data.sampler import Sampler\n",
        "\n",
        "import torchvision.transforms as T\n",
        "from torchvision.datasets import ImageFolder"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bu0y8g8gUmmz"
      },
      "source": [
        "## Data setup\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4p6zCFXskagK"
      },
      "source": [
        "\n",
        "Before we begin, lets mount the google drive to later on read information from it:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NeqA16HnUmmz"
      },
      "source": [
        "try:\n",
        "    from google.colab import drive\n",
        "    in_colab = True\n",
        "except ImportError:\n",
        "    in_colab = False"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjDGpTDvu_Dl"
      },
      "source": [
        "def unzip_file(zip_path, dest_path):\n",
        "    with ZipFile(zip_path, 'r') as zf:\n",
        "        for member in tqdm(zf.infolist(), desc='Extracting '):\n",
        "            zf.extract(member, dest_path)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NE6t24_MdGq"
      },
      "source": [
        "def unrar_files(tar_dir_path, dest_dir):\n",
        "    if not path.exists(dest_dir):\n",
        "        mkdir(dest_dir)\n",
        "    for dataset in ('Test', 'Training'):\n",
        "        tar_path = path.join(tar_dir_path, f'{dataset}.tar')\n",
        "        dest_folder = path.join(dest_dir, dataset)\n",
        "        if path.exists(dest_folder):\n",
        "            continue\n",
        "        mkdir(dest_folder)\n",
        "        extract_archive(tar_path, outdir=dest_folder)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a79Zqbf0pM4Y"
      },
      "source": [
        "minified = True"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7vrQkuNvBrE"
      },
      "source": [
        "def get_data_dir():\n",
        "    kaggle_path = '../input/ce888-dataset'\n",
        "    if path.exists(kaggle_path):\n",
        "        dest_dir = './data'\n",
        "        unrar_files(kaggle_path, dest_dir)\n",
        "        return dest_dir\n",
        "\n",
        "    general_dir = '.'\n",
        "    data_dir = general_dir + '/Flame'\n",
        "    if in_colab and not path.exists(data_dir):\n",
        "        drive_path = '/content/gdrive'\n",
        "        drive.mount(drive_path, force_remount=False)\n",
        "        zip_file = 'Minified-Flame.zip' if minified else 'Flame.zip'\n",
        "        zip_path = f'MyDrive/Essex/Datasets/zipped/{zip_file}'\n",
        "        unzip_file(path.join(drive_path, zip_path), general_dir)\n",
        "    return data_dir"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3P1wZc3yjqD"
      },
      "source": [
        "def get_model_dir():\n",
        "    return './Models'\n",
        "    return '/content/gdrive/MyDrive/Models/Lightning' if in_colab \\\n",
        "           else './Models'"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3XqUaGeNebYT"
      },
      "source": [
        "## Seed\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuutjrXRcWd7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e289e6f-adfb-4f3f-c0cf-83f98c874e9a"
      },
      "source": [
        "seed = 42\n",
        "pl.seed_everything(seed)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Global seed set to 42\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "42"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iixFi55mUmm1"
      },
      "source": [
        "## Datamodule preparation\n",
        "\n",
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TqYrYNWAQ18"
      },
      "source": [
        "A datamodule is a module that provides us _lightning_ to be able to structure our datadependencies in a more modular way\n",
        "\n",
        "In this case we will also declare transformations like the resize and the normalization. The normalization used are [the mean and std of the ImageNet dataset](https://github.com/rwightman/pytorch-image-models/blob/master/timm/data/constants.py)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81IxA3OC0PsK"
      },
      "source": [
        "### Helper classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdglgiCQNCUK"
      },
      "source": [
        "class BalancedBatchSampler(Sampler):\n",
        "    \"\"\"\n",
        "    Inspired by:\n",
        "    https://github.com/galatolofederico/pytorch-balanced-batch/blob/master/sampler.py\n",
        "    \"\"\"\n",
        "    def __init__(self, dataset, shuffle=False):\n",
        "        super().__init__(None)\n",
        "        self.dataset = dict()\n",
        "        real_dataset = dataset\n",
        "        while hasattr(real_dataset, 'dataset'):\n",
        "            real_dataset = real_dataset.dataset\n",
        "        self.balanced_max = 0\n",
        "        self.shuffle = shuffle\n",
        "        # Save all the indices for all the classes\n",
        "        for idx in range(0, len(dataset)):\n",
        "            label = self._get_label(real_dataset, idx)\n",
        "            if label not in self.dataset:\n",
        "                self.dataset[label] = list()\n",
        "            self.dataset[label].append(idx)\n",
        "            self.balanced_max = max(len(self.dataset[label]), self.balanced_max)\n",
        "\n",
        "        # Oversample the classes with fewer elements than the max\n",
        "        for label in self.dataset:\n",
        "            while len(self.dataset[label]) < self.balanced_max:\n",
        "                self.dataset[label].append(random.choice(self.dataset[label]))\n",
        "        self.keys = list(self.dataset.keys())\n",
        "        self.current_key = 0\n",
        "        self.indices = [-1]*len(self.keys)\n",
        "\n",
        "    @staticmethod\n",
        "    def _get_label(dataset, idx):\n",
        "        return dataset.imgs[idx][1]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.balanced_max*len(self.keys)\n",
        "\n",
        "    def __iter__(self):\n",
        "        if self.shuffle:\n",
        "            for key in self.keys:\n",
        "                random.shuffle(self.dataset[key])\n",
        "        while self.indices[self.current_key] < self.balanced_max - 1:\n",
        "            self.indices[self.current_key] += 1\n",
        "            label = self.keys[self.current_key]\n",
        "            index_label = self.indices[self.current_key]\n",
        "            yield self.dataset[label][index_label]\n",
        "            self.current_key = (self.current_key + 1) % len(self.keys)\n",
        "        self.indices = [-1]*len(self.keys)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPM2UAiV0cpL"
      },
      "source": [
        "### DataModule"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXy9kHAN8JV0"
      },
      "source": [
        "DEFAULT_BATCH_SIZE = 32\n",
        "DEFAULT_IMAGE_SIZE = (224, 224)\n",
        "STEPS = 1198 if minified else 2397\n",
        "\n",
        "class FlameDataModule(pl.LightningDataModule):\n",
        "    def __init__(\n",
        "            self,\n",
        "            batch_size=DEFAULT_BATCH_SIZE,\n",
        "            image_size=DEFAULT_IMAGE_SIZE\n",
        "        ):\n",
        "        super().__init__()\n",
        "        self.batch_size = batch_size\n",
        "        resize = T.Resize(image_size)\n",
        "        normalize = T.Normalize([0.485, 0.456, 0.406], \n",
        "                                [0.229, 0.224, 0.225])\n",
        "        toTensor = T.ToTensor()\n",
        "        self.train_transforms = T.Compose([\n",
        "            resize,\n",
        "            T.ColorJitter(brightness=0.1, contrast=0.1),\n",
        "            T.RandomRotation(degrees=45),\n",
        "            T.RandomHorizontalFlip(),\n",
        "            T.RandomVerticalFlip(),\n",
        "            toTensor,\n",
        "            normalize\n",
        "        ])\n",
        "        self.transforms = T.Compose([resize, toTensor, normalize])\n",
        "\n",
        "    def prepare_data(self):\n",
        "        self.data_dir = get_data_dir()\n",
        "    \n",
        "    def create_dataset(self, folder_name, transforms):\n",
        "        return ImageFolder(path.join(self.data_dir, folder_name), transforms)\n",
        "\n",
        "    def setup(self, stage=None):\n",
        "        if stage == 'fit' or stage is None:\n",
        "            self.train_ds = self.create_dataset('Training', self.train_transforms)\n",
        "            self.val_ds = self.create_dataset('Validation', self.transforms)\n",
        "        if stage == 'test' or stage is None:\n",
        "            self.test_ds = self.create_dataset('Test', self.transforms)\n",
        "\n",
        "    def _general_dataloader(self, dataset, **kwargs):\n",
        "        return DataLoader(\n",
        "            dataset, batch_size=self.batch_size, num_workers=2, drop_last=True,\n",
        "            pin_memory=True, **kwargs)\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        sampler = BalancedBatchSampler(self.train_ds, shuffle=True)\n",
        "        return self._general_dataloader(self.train_ds, sampler=sampler)\n",
        "        # print(len(loader))\n",
        "        # return loader\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return self._general_dataloader(self.val_ds)\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return self._general_dataloader(self.test_ds)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJCidcqFNrfU"
      },
      "source": [
        "datamodule = FlameDataModule()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F961Gb0ZUmm3"
      },
      "source": [
        "# Model \n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cd7xePlvUmm4"
      },
      "source": [
        "class PretrainedModel(pl.LightningModule):\n",
        "    def __init__(\n",
        "        self, name='rexnet_200', epochs=10, steps_per_epoch=100, lr=1e-3,\n",
        "        drop_rate=0.5, max_momentum=0.95\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.save_hyperparameters()\n",
        "        self.model = timm.create_model(name, pretrained=True,\n",
        "                                       num_classes=1, drop_rate=drop_rate)\n",
        "        self.just_train_classifier()\n",
        "\n",
        "        self.criterion = BCEWithLogitsLoss()\n",
        "        self.metrics = self.build_metrics()\n",
        "        self.transform = T.Compose([\n",
        "            T.RandomHorizontalFlip(),\n",
        "            T.RandomVerticalFlip()\n",
        "        ])\n",
        "    \n",
        "    def just_train_classifier(self):\n",
        "        self.freeze()\n",
        "        Freezer.make_trainable(self.model.get_classifier())\n",
        "\n",
        "    @staticmethod\n",
        "    def build_metrics():\n",
        "        general_metrics = [\n",
        "            Accuracy(compute_on_step=False),\n",
        "            F1(num_classes=2, compute_on_step=False)\n",
        "        ]\n",
        "        metric = MetricCollection(general_metrics)\n",
        "        return ModuleDict({\n",
        "            'test_metrics': metric.clone(),\n",
        "            'train_metrics': metric.clone(),\n",
        "            'val_metrics': metric.clone(),\n",
        "        })\n",
        "\n",
        "    def forward(self, x, tta = 0):\n",
        "        if tta == 0:\n",
        "            return self.model(x).squeeze(-1)\n",
        "        y_hat_stack = stack([self(self.transform(x)) for _ in range(tta)])\n",
        "        return y_hat_stack.mean(dim=0)\n",
        "    \n",
        "    def predict(self, x):\n",
        "        proba = sigmoid(self(x))\n",
        "        return (proba > 0.5).byte()\n",
        "\n",
        "    # Configurations\n",
        "    def configure_optimizers(self):\n",
        "        parameters = filter(lambda p: p.requires_grad, self.parameters())\n",
        "        optimizer = Adam(parameters, self.hparams.lr, weight_decay=1e-2)\n",
        "        # optimizer = Lookahead(optimizer)\n",
        "        scheduler = self._build_scheduler(optimizer)\n",
        "        scheduler_dict = {'scheduler': scheduler, 'interval': 'step'}\n",
        "        return [optimizer], [scheduler_dict]\n",
        "    \n",
        "    def _build_scheduler(self, optimizer):\n",
        "        lr, epochs = self.hparams.lr, self.hparams.epochs\n",
        "        max_momentum = self.hparams.max_momentum\n",
        "        base_momentum = max_momentum - 0.1\n",
        "        total_steps = epochs * self.hparams.steps_per_epoch\n",
        "        div_factor = epochs * 4\n",
        "        return OneCycleLR(\n",
        "            optimizer, lr, total_steps, pct_start=0.55, div_factor=div_factor,\n",
        "            final_div_factor=div_factor, three_phase=True,\n",
        "            max_momentum=max_momentum, base_momentum=base_momentum)\n",
        "\n",
        "    # Steps\n",
        "    def _get_dataset_metrics(self, dataset):\n",
        "        return self.metrics[f'{dataset}_metrics']\n",
        "\n",
        "    def _update_metrics(self, y_hat, y, dataset):\n",
        "        proba = sigmoid(y_hat)\n",
        "        self._get_dataset_metrics(dataset).update(proba, y)\n",
        "\n",
        "    def _on_step(self, batch, dataset):\n",
        "        x, y = batch\n",
        "        y_hat = self(x, 10)\n",
        "        loss = self.criterion(y_hat, y.float())\n",
        "        self._update_metrics(y_hat, y, dataset)\n",
        "        self.log(f'{dataset}_loss', loss, prog_bar=True)\n",
        "        return loss\n",
        "\n",
        "    def _on_end_epochs(self, outputs, dataset):\n",
        "        labels = [f'{dataset}_acc', f'{dataset}_f1']\n",
        "        metrics = self._get_dataset_metrics(dataset)\n",
        "        metrics_values = metrics.compute().values()\n",
        "        for label, value in zip(labels, metrics_values):\n",
        "            self.log(label, value)\n",
        "        if dataset != 'train':\n",
        "            score = stack(list(metrics_values)).mean()\n",
        "            self.log(f'{dataset}_score', score, prog_bar=True)\n",
        "        metrics.reset()\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        return self._on_step(batch, 'train')\n",
        "    \n",
        "    def training_epoch_end(self, outputs):\n",
        "        self._on_end_epochs(outputs, 'train')\n",
        "    \n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        return self._on_step(batch, 'val')\n",
        "\n",
        "    def validation_epoch_end(self, outputs):\n",
        "        self._on_end_epochs(outputs, 'val')\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        return self._on_step(batch, 'test')\n",
        "\n",
        "    def test_epoch_end(self, outputs):\n",
        "        self._on_end_epochs(outputs, 'test')"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCJL6DnTCrwK"
      },
      "source": [
        "# Callbacks\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7UW7W-u0PXYy"
      },
      "source": [
        "## Freezer class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnP01wWyD60E"
      },
      "source": [
        "class Freezer(pl_callbacks.BaseFinetuning):\n",
        "    trainable_layers = []\n",
        "\n",
        "    def __init__(\n",
        "        self, steps=4, unfreeze_per_step=8, train_bn=False, epochs=40\n",
        "    ):\n",
        "        self.step_size = ceil(epochs / (steps + 1))\n",
        "        self.unfreeze_per_step = unfreeze_per_step\n",
        "        self.train_bn = train_bn\n",
        "\n",
        "    @staticmethod\n",
        "    def flatten_children(module):\n",
        "        vanilla_children = list(module.children())\n",
        "        if len(vanilla_children) == 0:\n",
        "            return [module]\n",
        "        children = []\n",
        "        for child in vanilla_children:\n",
        "            child_children = Freezer.flatten_children(child)\n",
        "            children += child_children\n",
        "        return children\n",
        "\n",
        "    @staticmethod\n",
        "    def filter_non_trainable(children):\n",
        "        calc_num_params = lambda module: sum(p.numel() for p in module.parameters())\n",
        "        has_params = lambda module: calc_num_params(module) > 0\n",
        "        return list(filter(has_params, children))\n",
        "    \n",
        "    @staticmethod\n",
        "    def filter_non_frozen(children):\n",
        "        requires_grad = lambda p: p.requires_grad\n",
        "        is_frozen_module = \\\n",
        "            lambda module: len(list(filter(requires_grad, module.parameters()))) == 0\n",
        "        return list(filter(is_frozen_module, children))\n",
        "\n",
        "    @staticmethod\n",
        "    def trainable_children(pl_module, train_bn=False, reverse=False):\n",
        "        children = Freezer.flatten_children(pl_module)\n",
        "        children = Freezer.filter_non_trainable(children)\n",
        "        children = Freezer.filter_non_frozen(children)\n",
        "        if not train_bn:\n",
        "            is_not_bn = lambda mod: not isinstance(mod, _BatchNorm) \n",
        "            children = list(filter(is_not_bn, children))\n",
        "        if reverse:\n",
        "            children.reverse()\n",
        "        return children\n",
        "    \n",
        "    def freeze_before_training(self, pl_module):\n",
        "        self.trainable_layers = self.trainable_children(\n",
        "            pl_module, self.train_bn, reverse=True)\n",
        "    \n",
        "    def finetune_function(self, pl_module, current_epoch, optimizer, optimizer_idx):\n",
        "        trainable_layers_len = len(self.trainable_layers)\n",
        "        is_empty = trainable_layers_len == 0\n",
        "        is_finetune_epoch = current_epoch % self.step_size == 0 and \\\n",
        "                         current_epoch != 0\n",
        "        if not is_finetune_epoch or is_empty:\n",
        "            return\n",
        "        to_be_trained_layers = []\n",
        "        layers_to_be_freeze = min(self.unfreeze_per_step, trainable_layers_len)\n",
        "        for _ in range(layers_to_be_freeze):\n",
        "            to_be_trained_layers.append(self.trainable_layers.pop(0))\n",
        "        self.unfreeze_and_add_param_group(\n",
        "            to_be_trained_layers, optimizer, swa=True, one_cycle=True)\n",
        "\n",
        "    @staticmethod\n",
        "    def unfreeze_and_add_param_group(\n",
        "        modules,\n",
        "        optimizer,\n",
        "        swa = False,\n",
        "        one_cycle = False,\n",
        "        lr = None,\n",
        "        initial_denom_lr = 10.,\n",
        "        train_bn = True,\n",
        "    ):\n",
        "        Freezer.make_trainable(modules)\n",
        "        params_lr = optimizer.param_groups[0]['lr'] if lr is None else float(lr)\n",
        "        denom_lr = initial_denom_lr if lr is None else 1.\n",
        "        initial_lr = params_lr / denom_lr\n",
        "        params = Freezer.filter_params(modules, train_bn=train_bn, requires_grad=True)\n",
        "        params = Freezer.filter_on_optimizer(optimizer, params)\n",
        "        if params:\n",
        "            param_group = {\n",
        "                'params': params, 'lr': initial_lr, 'initial_lr': initial_lr,\n",
        "            }\n",
        "            extra_data = {}\n",
        "            if one_cycle:\n",
        "                extra_data = Freezer.momentum_param_group(optimizer)\n",
        "            if swa:\n",
        "                extra_data = { 'swa_lr': initial_lr, **extra_data }\n",
        "            param_group = { **param_group, **extra_data }\n",
        "            optimizer.add_param_group(param_group)\n",
        "\n",
        "    @staticmethod\n",
        "    def momentum_param_group(optimizer):\n",
        "        group = optimizer.param_groups[0]\n",
        "        momentum_group = {\n",
        "            'base_momentum': group['base_momentum'],\n",
        "            'max_momentum': group['max_momentum'],\n",
        "            'max_lr': group['max_lr'],\n",
        "            'min_lr': group['min_lr'],\n",
        "        }\n",
        "        extra_group = {\n",
        "            'betas': group['betas']\n",
        "        } if 'betas' in optimizer.defaults else {\n",
        "            'momentum': group['momentum']\n",
        "        }\n",
        "        return { **momentum_group, **extra_group }"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kh9nEppHc2BG"
      },
      "source": [
        "## ProgressBar class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rV6ZiB0nc1Wk"
      },
      "source": [
        "class ProgressBar(pl_callbacks.ProgressBarBase):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.epoch_time = 0\n",
        "        self.stage_time = 0\n",
        "    \n",
        "    def disable(self):\n",
        "        pass\n",
        "    \n",
        "    def enable(self):\n",
        "        pass\n",
        "\n",
        "    @staticmethod\n",
        "    def format_num(n) -> str:\n",
        "        \"\"\" Add additional padding to the formatted numbers \"\"\"\n",
        "        should_be_padded = isinstance(n, (float, str))\n",
        "        if not isinstance(n, str):\n",
        "            n = tqdm.format_num(n)\n",
        "        if should_be_padded and 'e' not in n:\n",
        "            if '.' not in n and len(n) < 5:\n",
        "                try:\n",
        "                    _ = float(n)\n",
        "                except ValueError:\n",
        "                    return n\n",
        "                n += '.'\n",
        "            n += \"0\" * (5 - len(n))\n",
        "        return n\n",
        "    \n",
        "    def get_formatted_duration(self, prev_time):\n",
        "        duration = time() - prev_time\n",
        "        if duration < 60:\n",
        "            unit = 's'\n",
        "        elif duration < 3600:\n",
        "            duration /= 60\n",
        "            unit = 'm'\n",
        "        else:\n",
        "            duration /= 3600\n",
        "            unit = 'h'\n",
        "        return self.format_num(duration) + unit\n",
        "    \n",
        "    def on_train_start(self, trainer, pl_module):\n",
        "        self.stage_time = time()\n",
        "        print('Start training')\n",
        "\n",
        "    def on_train_end(self, trainer, pl_module):\n",
        "        print(f'Total duration: {self.get_formatted_duration(self.stage_time)}')\n",
        "    \n",
        "    def on_train_epoch_start(self, trainer, pl_module):\n",
        "        self.epoch_time = time()\n",
        "    \n",
        "    def on_validation_epoch_end(self, trainer, pl_module):\n",
        "        values = [\n",
        "            f'Epoch: {trainer.current_epoch}',\n",
        "            f'Time: {self.get_formatted_duration(self.epoch_time)}'\n",
        "        ]\n",
        "        values += [\n",
        "            f'{key}: {self.format_num(value)}'\n",
        "            for key, value in trainer.progress_bar_dict.items()\n",
        "        ]\n",
        "        print(' - '.join(values))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCOLnxQePb1b"
      },
      "source": [
        "## Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57HupS7lBJ4C"
      },
      "source": [
        "def get_checkpoint(model_name):\n",
        "    filename = '{epoch:02d}-{val_score:.4f}'\n",
        "    production_dirpath = path.join(get_model_dir(), model_name)\n",
        "    dirpath = production_dirpath if production_mode else model_name\n",
        "    return pl_callbacks.ModelCheckpoint(\n",
        "        dirpath=dirpath, monitor='val_score', mode='max', filename=filename)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StGH-GbjA99v"
      },
      "source": [
        "def get_callbacks(model_name, epochs):\n",
        "    checkpoint = get_checkpoint(model_name)\n",
        "    freezer = Freezer(epochs=epochs)\n",
        "    progress_bar = ProgressBar()\n",
        "    return [checkpoint, freezer, progress_bar]"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2t8iJ38PRaE"
      },
      "source": [
        "# Trainer\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4bdyXZPOn7-"
      },
      "source": [
        "def get_accelerator():\n",
        "    tpu_device_exists = xla_device.XLADeviceUtils().tpu_device_exists()\n",
        "    has_gpu = cuda.is_available()\n",
        "\n",
        "    return {'tpu_cores': 8} if tpu_device_exists else \\\n",
        "           {'gpus': cuda.device_count()} if has_gpu else {}"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jny1pcEGOpnN"
      },
      "source": [
        "max_epochs = 5\n",
        "production_mode = True\n",
        "\n",
        "def create_trainer(model_name, **kwargs):\n",
        "    callbacks = get_callbacks(model_name, max_epochs)\n",
        "    accelerator = get_accelerator()\n",
        "    return pl.Trainer(\n",
        "        max_epochs=max_epochs, deterministic=True, benchmark=True,\n",
        "        callbacks=callbacks, precision=16, stochastic_weight_avg=False,\n",
        "        **accelerator, **kwargs)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kEzlvDeNF3q"
      },
      "source": [
        "# Tuning\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_e34IyRNHnU"
      },
      "source": [
        "def find_best_and_substitute_lr(model, **kwargs):\n",
        "    trainer = create_trainer(model.hparams.name, auto_lr_find=True, **kwargs)\n",
        "    if trainer.fast_dev_run:\n",
        "        return\n",
        "    lr_finder = trainer.tuner.lr_find(\n",
        "        model, early_stop_threshold=None, min_lr=3e-4, max_lr=9e-2,\n",
        "        datamodule=datamodule, num_training=400)\n",
        "    lr_finder.plot(suggest=True, show=True)\n",
        "    suggest_lr = lr_finder.results['lr'][lr_finder._optimal_idx]\n",
        "    model.hparams.lr = suggest_lr"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCeMVuy-A4Ri"
      },
      "source": [
        "# Training and testing\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GFiyQOl-jZi"
      },
      "source": [
        "def create_fit_and_test(model_name, **kwargs):\n",
        "    model = PretrainedModel(model_name, max_epochs, STEPS)\n",
        "    find_best_and_substitute_lr(model, **kwargs)\n",
        "    print(f'Training with max lr of {model.hparams.lr:.2e}')\n",
        "    trainer = create_trainer(model.hparams.name, **kwargs)\n",
        "    trainer.fit(model, datamodule=datamodule)\n",
        "    trainer.test(model, datamodule=datamodule)\n",
        "    cuda.empty_cache()"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5llRfok5hhwZ"
      },
      "source": [
        "# Models results\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IUetDolrkiD",
        "outputId": "0c28ab29-e09a-4434-e126-23ac52f07023",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "c7094d4c3994435abc4ff162b0a11b28",
            "85747c1886ce436a8050a9734eaa5ad3",
            "74636bca876f4c18b737ddccb0872d09",
            "1a5661e09c394af9a881778b25107266",
            "43e1bb7ccd1541e9a120ea2de10e411e",
            "d398a8470fc242f4aafc5bd10ed2a393",
            "16116875252e41d3878332fc1cf48ce3",
            "8d46f3de582a46d2ae89ad9637d74435"
          ]
        }
      },
      "source": [
        "create_fit_and_test('gernet_m')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU available: True, used: True\n",
            "TPU available: None, using: 0 TPU cores\n",
            "Using native 16bit precision.\n",
            "\n",
            "  | Name      | Type              | Params\n",
            "------------------------------------------------\n",
            "0 | model     | ByobNet           | 18.6 M\n",
            "1 | criterion | BCEWithLogitsLoss | 0     \n",
            "2 | metrics   | ModuleDict        | 0     \n",
            "------------------------------------------------\n",
            "2.6 K     Trainable params\n",
            "18.6 M    Non-trainable params\n",
            "18.6 M    Total params\n",
            "74.338    Total estimated model params size (MB)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c7094d4c3994435abc4ff162b0a11b28",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Finding best initial lr', max=400.0, style=ProgressStyle(â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Restored states from the checkpoint file at /content/lr_find_temp_model.ckpt\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "GPU available: True, used: True\n",
            "TPU available: None, using: 0 TPU cores\n",
            "Using native 16bit precision.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training with max lr of 2.92e-04\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  | Name      | Type              | Params\n",
            "------------------------------------------------\n",
            "0 | model     | ByobNet           | 18.6 M\n",
            "1 | criterion | BCEWithLogitsLoss | 0     \n",
            "2 | metrics   | ModuleDict        | 0     \n",
            "------------------------------------------------\n",
            "2.6 K     Trainable params\n",
            "18.6 M    Non-trainable params\n",
            "18.6 M    Total params\n",
            "74.338    Total estimated model params size (MB)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0 - Time: 4.49e+5h - loss: nan.0 - v_num: 2 - val_loss: 0.740 - val_score: 0.0781\n",
            "Start training\n",
            "Epoch: 0 - Time: 6.400m - loss: 0.337 - v_num: 2 - val_loss: 0.350 - val_score: 0.907 - train_loss: 0.280\n",
            "Epoch: 1 - Time: 7.730m - loss: 0.0829 - v_num: 2 - val_loss: 0.0639 - val_score: 0.985 - train_loss: 0.0262\n",
            "Epoch: 2 - Time: 9.260m - loss: 0.0638 - v_num: 2 - val_loss: 0.0587 - val_score: 0.980 - train_loss: 0.0358\n",
            "Epoch: 3 - Time: 10.30m - loss: 0.041 - v_num: 2 - val_loss: 0.0512 - val_score: 0.982 - train_loss: 0.0508\n",
            "Epoch: 4 - Time: 11.10m - loss: 0.0747 - v_num: 2 - val_loss: 0.034 - val_score: 0.987 - train_loss: 0.072\n",
            "Total duration: 44.90m\n",
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{'test_acc': 0.7739312052726746,\n",
            " 'test_f1': 0.669833779335022,\n",
            " 'test_loss': 0.5406481027603149,\n",
            " 'test_score': 0.7218824625015259}\n",
            "--------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZfRQL75VVI2M"
      },
      "source": [
        "create_fit_and_test('repvgg_b0')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKeBxyitVglV"
      },
      "source": [
        "create_fit_and_test('rexnet_200')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fQ9TrlQV2PD"
      },
      "source": [
        "create_fit_and_test('tf_efficientnet_b4')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kerG8vMIuPie"
      },
      "source": [
        "# %load_ext tensorboard\n",
        "# %tensorboard --logdir /content/lightning_logs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QaZcJHqkfTYK"
      },
      "source": [
        "# !mv /content/lightning_logs /content/gdrive/MyDrive/Models/logs"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}