{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Training.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "mUUtCI6-nJH5",
        "IKioRsqnkdCH",
        "Bu0y8g8gUmmz",
        "3XqUaGeNebYT",
        "iixFi55mUmm1",
        "81IxA3OC0PsK",
        "VPM2UAiV0cpL",
        "F961Gb0ZUmm3",
        "mCJL6DnTCrwK",
        "7UW7W-u0PXYy",
        "Kh9nEppHc2BG",
        "vCOLnxQePb1b",
        "i2t8iJ38PRaE",
        "2kEzlvDeNF3q",
        "bCeMVuy-A4Ri",
        "5llRfok5hhwZ"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python [default]",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f700ce925181449c9b51d8b483b6fae0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ea2b53dfe38e43a2b45dfafdba8cb2fc",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f8846514e4384c19a09aca60449dac2d",
              "IPY_MODEL_c03b16509e394d7d9536270528cf323f"
            ]
          }
        },
        "ea2b53dfe38e43a2b45dfafdba8cb2fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f8846514e4384c19a09aca60449dac2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_bfd284648dd5450987e959b7d964a542",
            "_dom_classes": [],
            "description": "Finding best initial lr: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 100,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 100,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_aaeeedbc83524fd18ba917197ed2bb01"
          }
        },
        "c03b16509e394d7d9536270528cf323f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7507a7233477476fac578ebd3a35255f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 100/100 [00:17&lt;00:00,  5.94it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c5e6d43c87994af0a9f8d72d46776473"
          }
        },
        "bfd284648dd5450987e959b7d964a542": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "aaeeedbc83524fd18ba917197ed2bb01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7507a7233477476fac578ebd3a35255f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c5e6d43c87994af0a9f8d72d46776473": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ricglz/CE888_activities/blob/main/assignment/Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUUtCI6-nJH5"
      },
      "source": [
        "# Normally constant aspects (doesn't require as much config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKioRsqnkdCH"
      },
      "source": [
        "## Install dependencies\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jR0i3ECTUmmx"
      },
      "source": [
        "!pip --quiet install torch torchvision patool timm pytorch-lightning"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lfg7Kyt4i7Av"
      },
      "source": [
        "from math import ceil\n",
        "from os import path, mkdir\n",
        "from pandas import DataFrame\n",
        "from patoolib import extract_archive\n",
        "from sklearn.model_selection import train_test_split\n",
        "from time import time\n",
        "from tqdm import tqdm\n",
        "from zipfile import ZipFile\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import seaborn as sns\n",
        "import sys\n",
        "import timm\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "import pytorch_lightning.callbacks as pl_callbacks\n",
        "from pytorch_lightning.utilities import xla_device\n",
        "from pytorch_lightning.loggers import TensorBoardLogger\n",
        "from pytorch_lightning.metrics import Accuracy, ConfusionMatrix, \\\n",
        "                                      MetricCollection, F1\n",
        "\n",
        "from torch import cuda, sigmoid, stack, use_deterministic_algorithms\n",
        "from torch.nn import BCEWithLogitsLoss, ModuleDict\n",
        "from torch.nn.modules.batchnorm import _BatchNorm\n",
        "from torch.optim import Adam, AdamW, RMSprop, SGD\n",
        "from torch.optim.lr_scheduler import OneCycleLR\n",
        "from torch.utils.data import DataLoader, Dataset, Subset, random_split\n",
        "from torch.utils.data.sampler import Sampler\n",
        "\n",
        "import torchvision.transforms as T\n",
        "from torchvision.datasets import ImageFolder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bu0y8g8gUmmz"
      },
      "source": [
        "## Data setup\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4p6zCFXskagK"
      },
      "source": [
        "\n",
        "Before we begin, lets mount the google drive to later on read information from it:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NeqA16HnUmmz"
      },
      "source": [
        "try:\n",
        "    from google.colab import drive\n",
        "    in_colab = True\n",
        "except ImportError:\n",
        "    in_colab = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjDGpTDvu_Dl"
      },
      "source": [
        "def unzip_file(zip_path, dest_path):\n",
        "    with ZipFile(zip_path, 'r') as zf:\n",
        "        for member in tqdm(zf.infolist(), desc='Extracting '):\n",
        "            zf.extract(member, dest_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NE6t24_MdGq"
      },
      "source": [
        "def unrar_files(tar_dir_path, dest_dir):\n",
        "    if not path.exists(dest_dir):\n",
        "        mkdir(dest_dir)\n",
        "    for dataset in ('Test', 'Training'):\n",
        "        tar_path = path.join(tar_dir_path, f'{dataset}.tar')\n",
        "        dest_folder = path.join(dest_dir, dataset)\n",
        "        if path.exists(dest_folder):\n",
        "            continue\n",
        "        mkdir(dest_folder)\n",
        "        extract_archive(tar_path, outdir=dest_folder)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a79Zqbf0pM4Y"
      },
      "source": [
        "minified = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7vrQkuNvBrE"
      },
      "source": [
        "def get_data_dir():\n",
        "    kaggle_path = '../input/ce888-dataset'\n",
        "    if path.exists(kaggle_path):\n",
        "        dest_dir = './data'\n",
        "        unrar_files(kaggle_path, dest_dir)\n",
        "        return dest_dir\n",
        "\n",
        "    general_dir = '.'\n",
        "    data_dir = general_dir + '/Flame'\n",
        "    if in_colab and not path.exists(data_dir):\n",
        "        drive_path = '/content/gdrive'\n",
        "        drive.mount(drive_path, force_remount=False)\n",
        "        zip_file = 'Minified-Flame.zip' if minified else 'Flame.zip'\n",
        "        zip_path = f'MyDrive/Essex/Datasets/zipped/{zip_file}'\n",
        "        unzip_file(path.join(drive_path, zip_path), general_dir)\n",
        "    return data_dir"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3P1wZc3yjqD"
      },
      "source": [
        "def get_model_dir():\n",
        "    return './Models'\n",
        "    return '/content/gdrive/MyDrive/Models/Lightning' if in_colab \\\n",
        "           else './Models'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3XqUaGeNebYT"
      },
      "source": [
        "## Seed\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuutjrXRcWd7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85f5c8a5-ce4b-4c93-fd81-9f5b21124309"
      },
      "source": [
        "seed = 42\n",
        "pl.seed_everything(seed)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Global seed set to 42\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "42"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iixFi55mUmm1"
      },
      "source": [
        "## Datamodule preparation\n",
        "\n",
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TqYrYNWAQ18"
      },
      "source": [
        "A datamodule is a module that provides us _lightning_ to be able to structure our datadependencies in a more modular way\n",
        "\n",
        "In this case we will also declare transformations like the resize and the normalization. The normalization used are [the mean and std of the ImageNet dataset](https://github.com/rwightman/pytorch-image-models/blob/master/timm/data/constants.py)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81IxA3OC0PsK"
      },
      "source": [
        "### Helper classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdglgiCQNCUK"
      },
      "source": [
        "class BalancedBatchSampler(Sampler):\n",
        "    \"\"\"\n",
        "    Inspired by:\n",
        "    https://github.com/galatolofederico/pytorch-balanced-batch/blob/master/sampler.py\n",
        "    \"\"\"\n",
        "    def __init__(self, dataset, shuffle=False):\n",
        "        super().__init__(None)\n",
        "        self.dataset = dict()\n",
        "        real_dataset = dataset\n",
        "        while hasattr(real_dataset, 'dataset'):\n",
        "            real_dataset = real_dataset.dataset\n",
        "        self.balanced_max = 0\n",
        "        self.shuffle = shuffle\n",
        "        # Save all the indices for all the classes\n",
        "        for idx in range(0, len(dataset)):\n",
        "            label = self._get_label(real_dataset, idx)\n",
        "            if label not in self.dataset:\n",
        "                self.dataset[label] = list()\n",
        "            self.dataset[label].append(idx)\n",
        "            self.balanced_max = max(len(self.dataset[label]), self.balanced_max)\n",
        "\n",
        "        # Oversample the classes with fewer elements than the max\n",
        "        for label in self.dataset:\n",
        "            while len(self.dataset[label]) < self.balanced_max:\n",
        "                self.dataset[label].append(random.choice(self.dataset[label]))\n",
        "        self.keys = list(self.dataset.keys())\n",
        "        self.current_key = 0\n",
        "        self.indices = [-1]*len(self.keys)\n",
        "\n",
        "    @staticmethod\n",
        "    def _get_label(dataset, idx):\n",
        "        return dataset.imgs[idx][1]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.balanced_max*len(self.keys)\n",
        "\n",
        "    def __iter__(self):\n",
        "        if self.shuffle:\n",
        "            for key in self.keys:\n",
        "                random.shuffle(self.dataset[key])\n",
        "        while self.indices[self.current_key] < self.balanced_max - 1:\n",
        "            self.indices[self.current_key] += 1\n",
        "            label = self.keys[self.current_key]\n",
        "            index_label = self.indices[self.current_key]\n",
        "            yield self.dataset[label][index_label]\n",
        "            self.current_key = (self.current_key + 1) % len(self.keys)\n",
        "        self.indices = [-1]*len(self.keys)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPM2UAiV0cpL"
      },
      "source": [
        "### DataModule"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXy9kHAN8JV0"
      },
      "source": [
        "DEFAULT_BATCH_SIZE = 32\n",
        "DEFAULT_IMAGE_SIZE = (224, 224)\n",
        "STEPS = 1198 if minified else 2397\n",
        "\n",
        "class FlameDataModule(pl.LightningDataModule):\n",
        "    def __init__(\n",
        "            self,\n",
        "            batch_size=DEFAULT_BATCH_SIZE,\n",
        "            image_size=DEFAULT_IMAGE_SIZE\n",
        "        ):\n",
        "        super().__init__()\n",
        "        self.batch_size = batch_size\n",
        "        resize = T.Resize(image_size)\n",
        "        normalize = T.Normalize([0.485, 0.456, 0.406], \n",
        "                                [0.229, 0.224, 0.225])\n",
        "        toTensor = T.ToTensor()\n",
        "        self.train_transforms = T.Compose([\n",
        "            resize,\n",
        "            T.ColorJitter(brightness=0.1, contrast=0.1),\n",
        "            T.RandomRotation(degrees=5),\n",
        "            T.RandomHorizontalFlip(),\n",
        "            T.RandomVerticalFlip(),\n",
        "            toTensor,\n",
        "            normalize\n",
        "        ])\n",
        "        self.transforms = T.Compose([resize, toTensor, normalize])\n",
        "\n",
        "    def prepare_data(self):\n",
        "        self.data_dir = get_data_dir()\n",
        "\n",
        "    def setup(self, stage=None):\n",
        "        if stage == 'fit' or stage is None:\n",
        "            train_dir = path.join(self.data_dir, 'Training')\n",
        "            val_dir = path.join(self.data_dir, 'Validation')\n",
        "            self.train_dir = ImageFolder(train_dir, self.train_transforms)\n",
        "            self.train_dir = ImageFolder(val_dir, self.transforms)\n",
        "        if stage == 'test' or stage is None:\n",
        "            testing_dir = path.join(self.data_dir, 'Test')\n",
        "            self.test_ds = ImageFolder(testing_dir, transform=self.transforms)\n",
        "\n",
        "    def _general_dataloader(self, dataset, **kwargs):\n",
        "        return DataLoader(\n",
        "            dataset, batch_size=self.batch_size, num_workers=2, drop_last=True,\n",
        "            pin_memory=True, **kwargs)\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        sampler = BalancedBatchSampler(self.train_ds, shuffle=True)\n",
        "        return self._general_dataloader(self.train_ds, sampler=sampler)\n",
        "        # print(len(loader))\n",
        "        # return loader\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return self._general_dataloader(self.val_ds)\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return self._general_dataloader(self.test_ds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJCidcqFNrfU"
      },
      "source": [
        "datamodule = FlameDataModule()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F961Gb0ZUmm3"
      },
      "source": [
        "# Model \n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cd7xePlvUmm4"
      },
      "source": [
        "class PretrainedModel(pl.LightningModule):\n",
        "    def __init__(\n",
        "        self, name='rexnet_200', epochs=10, steps_per_epoch=100, lr=1e-3,\n",
        "        drop_rate=0.5\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.save_hyperparameters()\n",
        "        self.model = timm.create_model(name, pretrained=True,\n",
        "                                       num_classes=1, drop_rate=drop_rate)\n",
        "        self.just_train_classifier()\n",
        "\n",
        "        self.criterion = BCEWithLogitsLoss()\n",
        "        self.metrics = self.build_metrics()\n",
        "        self.transform = T.Compose([\n",
        "            T.RandomHorizontalFlip(),\n",
        "            T.RandomVerticalFlip()\n",
        "        ])\n",
        "    \n",
        "    def just_train_classifier(self):\n",
        "        self.freeze()\n",
        "        Freezer.make_trainable(self.model.get_classifier())\n",
        "\n",
        "    @staticmethod\n",
        "    def build_metrics():\n",
        "        general_metrics = [\n",
        "            Accuracy(compute_on_step=False),\n",
        "            F1(num_classes=2, compute_on_step=False)\n",
        "        ]\n",
        "        metric = MetricCollection(general_metrics)\n",
        "        return ModuleDict({\n",
        "            'test_metrics': metric.clone(),\n",
        "            'train_metrics': metric.clone(),\n",
        "            'val_metrics': metric.clone(),\n",
        "        })\n",
        "\n",
        "    def forward(self, x, tta = 0):\n",
        "        if tta == 0:\n",
        "            return self.model(x).squeeze(-1)\n",
        "        y_hat_stack = stack([self(self.transform(x)) for _ in range(tta)])\n",
        "        return y_hat_stack.mean(dim=0)\n",
        "    \n",
        "    def predict(self, x):\n",
        "        proba = sigmoid(self(x))\n",
        "        return (proba > 0.5).byte()\n",
        "\n",
        "    # Configurations\n",
        "    def configure_optimizers(self):\n",
        "        parameters = filter(lambda p: p.requires_grad, self.parameters())\n",
        "        optimizer = RMSprop(\n",
        "            parameters, self.hparams.lr, momentum=0.9, weight_decay=7.5e-3)\n",
        "        # optimizer = Lookahead(optimizer)\n",
        "        total_steps = self.hparams.epochs * self.hparams.steps_per_epoch\n",
        "        scheduler = OneCycleLR(\n",
        "            optimizer, self.hparams.lr, total_steps=total_steps, pct_start=0.55,\n",
        "            div_factor=25, final_div_factor=25, three_phase=True)\n",
        "        scheduler_dict = {'scheduler': scheduler, 'interval': 'step'}\n",
        "        return [optimizer], [scheduler_dict]\n",
        "\n",
        "    # Steps\n",
        "    def _get_dataset_metrics(self, dataset):\n",
        "        return self.metrics[f'{dataset}_metrics']\n",
        "\n",
        "    def _update_metrics(self, y_hat, y, dataset):\n",
        "        proba = sigmoid(y_hat)\n",
        "        self._get_dataset_metrics(dataset).update(proba, y)\n",
        "\n",
        "    def _on_step(self, batch, dataset):\n",
        "        x, y = batch\n",
        "        y_hat = self(x, 5)\n",
        "        loss = self.criterion(y_hat, y.float())\n",
        "        self._update_metrics(y_hat, y, dataset)\n",
        "        self.log(f'{dataset}_loss', loss, prog_bar=True)\n",
        "        return loss\n",
        "\n",
        "    def _on_end_epochs(self, outputs, dataset):\n",
        "        labels = [f'{dataset}_acc', f'{dataset}_f1']\n",
        "        metrics = self._get_dataset_metrics(dataset)\n",
        "        metrics_values = metrics.compute().values()\n",
        "        for label, value in zip(labels, metrics_values):\n",
        "            self.log(label, value)\n",
        "        if dataset != 'train':\n",
        "            score = stack(list(metrics_values)).mean()\n",
        "            self.log(f'{dataset}_score', score, prog_bar=True)\n",
        "        metrics.reset()\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        return self._on_step(batch, 'train')\n",
        "    \n",
        "    def training_epoch_end(self, outputs):\n",
        "        self._on_end_epochs(outputs, 'train')\n",
        "    \n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        return self._on_step(batch, 'val')\n",
        "\n",
        "    def validation_epoch_end(self, outputs):\n",
        "        self._on_end_epochs(outputs, 'val')\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        return self._on_step(batch, 'test')\n",
        "\n",
        "    def test_epoch_end(self, outputs):\n",
        "        self._on_end_epochs(outputs, 'test')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCJL6DnTCrwK"
      },
      "source": [
        "# Callbacks\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7UW7W-u0PXYy"
      },
      "source": [
        "## Freezer class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnP01wWyD60E"
      },
      "source": [
        "class Freezer(pl_callbacks.BaseFinetuning):\n",
        "    trainable_layers = []\n",
        "\n",
        "    def __init__(\n",
        "        self, steps=4, unfreeze_per_step=4, train_bn=True, epochs=40\n",
        "    ):\n",
        "        self.step_size = ceil(epochs / (steps + 1))\n",
        "        self.unfreeze_per_step = unfreeze_per_step\n",
        "        self.train_bn = train_bn\n",
        "\n",
        "    @staticmethod\n",
        "    def flatten_children(module):\n",
        "        vanilla_children = list(module.children())\n",
        "        if len(vanilla_children) == 0:\n",
        "            return [module]\n",
        "        children = []\n",
        "        for child in vanilla_children:\n",
        "            child_children = Freezer.flatten_children(child)\n",
        "            children += child_children\n",
        "        return children\n",
        "\n",
        "    @staticmethod\n",
        "    def filter_non_trainable(children):\n",
        "        calc_num_params = lambda module: sum(p.numel() for p in module.parameters())\n",
        "        has_params = lambda module: calc_num_params(module) > 0\n",
        "        return list(filter(has_params, children))\n",
        "    \n",
        "    @staticmethod\n",
        "    def filter_non_frozen(children):\n",
        "        requires_grad = lambda p: p.requires_grad\n",
        "        is_frozen_module = \\\n",
        "            lambda module: len(list(filter(requires_grad, module.parameters()))) == 0\n",
        "        return list(filter(is_frozen_module, children))\n",
        "\n",
        "    @staticmethod\n",
        "    def trainable_children(pl_module, train_bn=False, reverse=False):\n",
        "        children = Freezer.flatten_children(pl_module)\n",
        "        children = Freezer.filter_non_trainable(children)\n",
        "        children = Freezer.filter_non_frozen(children)\n",
        "        if not train_bn:\n",
        "            is_not_bn = lambda mod: not isinstance(mod, _BatchNorm) \n",
        "            children = list(filter(is_not_bn, children))\n",
        "        if reverse:\n",
        "            children.reverse()\n",
        "        return children\n",
        "    \n",
        "    def freeze_before_training(self, pl_module):\n",
        "        self.trainable_layers = self.trainable_children(\n",
        "            pl_module, self.train_bn, reverse=True)\n",
        "    \n",
        "    def finetune_function(self, pl_module, current_epoch, optimizer, optimizer_idx):\n",
        "        trainable_layers_len = len(self.trainable_layers)\n",
        "        is_empty = trainable_layers_len == 0\n",
        "        is_finetune_epoch = current_epoch % self.step_size == 0 and \\\n",
        "                         current_epoch != 0\n",
        "        if not is_finetune_epoch or is_empty:\n",
        "            return\n",
        "        to_be_trained_layers = []\n",
        "        layers_to_be_freeze = min(self.unfreeze_per_step, trainable_layers_len)\n",
        "        for _ in range(layers_to_be_freeze):\n",
        "            to_be_trained_layers.append(self.trainable_layers.pop(0))\n",
        "        self.unfreeze_and_add_param_group(\n",
        "            to_be_trained_layers, optimizer, swa=True, one_cycle=True)\n",
        "\n",
        "    @staticmethod\n",
        "    def unfreeze_and_add_param_group(\n",
        "        modules,\n",
        "        optimizer,\n",
        "        swa = False,\n",
        "        one_cycle = False,\n",
        "        lr = None,\n",
        "        initial_denom_lr = 10.,\n",
        "        train_bn = True,\n",
        "    ):\n",
        "        Freezer.make_trainable(modules)\n",
        "        params_lr = optimizer.param_groups[0]['lr'] if lr is None else float(lr)\n",
        "        denom_lr = initial_denom_lr if lr is None else 1.\n",
        "        initial_lr = params_lr / denom_lr\n",
        "        params = Freezer.filter_params(modules, train_bn=train_bn, requires_grad=True)\n",
        "        params = Freezer.filter_on_optimizer(optimizer, params)\n",
        "        if params:\n",
        "            param_group = {\n",
        "                'params': params, 'lr': initial_lr, 'initial_lr': initial_lr,\n",
        "            }\n",
        "            extra_data = {}\n",
        "            if one_cycle:\n",
        "                extra_data = Freezer.momentum_param_group(optimizer)\n",
        "            if swa:\n",
        "                extra_data = { 'swa_lr': initial_lr, **extra_data }\n",
        "            param_group = { **param_group, **extra_data }\n",
        "            optimizer.add_param_group(param_group)\n",
        "\n",
        "    @staticmethod\n",
        "    def momentum_param_group(optimizer):\n",
        "        group = optimizer.param_groups[0]\n",
        "        momentum_group = {\n",
        "            'base_momentum': group['base_momentum'],\n",
        "            'max_momentum': group['max_momentum'],\n",
        "            'max_lr': group['max_lr'],\n",
        "            'min_lr': group['min_lr'],\n",
        "        }\n",
        "        extra_group = {\n",
        "            'betas': group['betas']\n",
        "        } if 'betas' in optimizer.defaults else {\n",
        "            'momentum': group['momentum']\n",
        "        }\n",
        "        return { **momentum_group, **extra_group }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kh9nEppHc2BG"
      },
      "source": [
        "## ProgressBar class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rV6ZiB0nc1Wk"
      },
      "source": [
        "class ProgressBar(pl_callbacks.ProgressBarBase):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.epoch_time = 0\n",
        "        self.stage_time = 0\n",
        "    \n",
        "    def disable(self):\n",
        "        pass\n",
        "    \n",
        "    def enable(self):\n",
        "        pass\n",
        "\n",
        "    @staticmethod\n",
        "    def format_num(n) -> str:\n",
        "        \"\"\" Add additional padding to the formatted numbers \"\"\"\n",
        "        should_be_padded = isinstance(n, (float, str))\n",
        "        if not isinstance(n, str):\n",
        "            n = tqdm.format_num(n)\n",
        "        if should_be_padded and 'e' not in n:\n",
        "            if '.' not in n and len(n) < 5:\n",
        "                try:\n",
        "                    _ = float(n)\n",
        "                except ValueError:\n",
        "                    return n\n",
        "                n += '.'\n",
        "            n += \"0\" * (5 - len(n))\n",
        "        return n\n",
        "    \n",
        "    def get_formatted_duration(self, prev_time):\n",
        "        duration = time() - prev_time\n",
        "        if duration < 60:\n",
        "            unit = 's'\n",
        "        elif duration < 3600:\n",
        "            duration /= 60\n",
        "            unit = 'm'\n",
        "        else:\n",
        "            duration /= 3600\n",
        "            unit = 'h'\n",
        "        return self.format_num(duration) + unit\n",
        "    \n",
        "    def on_train_start(self, trainer, pl_module):\n",
        "        self.stage_time = time()\n",
        "        print('Start training')\n",
        "\n",
        "    def on_train_end(self, trainer, pl_module):\n",
        "        print(f'Total duration: {self.get_formatted_duration(self.stage_time)}')\n",
        "    \n",
        "    def on_train_epoch_start(self, trainer, pl_module):\n",
        "        self.epoch_time = time()\n",
        "    \n",
        "    def on_validation_epoch_end(self, trainer, pl_module):\n",
        "        values = [\n",
        "            f'Epoch: {trainer.current_epoch}',\n",
        "            f'Time: {self.get_formatted_duration(self.epoch_time)}'\n",
        "        ]\n",
        "        values += [\n",
        "            f'{key}: {self.format_num(value)}'\n",
        "            for key, value in trainer.progress_bar_dict.items()\n",
        "        ]\n",
        "        print(' - '.join(values))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCOLnxQePb1b"
      },
      "source": [
        "## Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57HupS7lBJ4C"
      },
      "source": [
        "def get_checkpoint(model_name):\n",
        "    filename = '{epoch:02d}-{val_score:.4f}'\n",
        "    production_dirpath = path.join(get_model_dir(), model_name)\n",
        "    dirpath = production_dirpath if production_mode else model_name\n",
        "    return pl_callbacks.ModelCheckpoint(\n",
        "        dirpath=dirpath, monitor='val_score', mode='max', filename=filename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StGH-GbjA99v"
      },
      "source": [
        "def get_callbacks(model_name, epochs):\n",
        "    checkpoint = get_checkpoint(model_name)\n",
        "    freezer = Freezer(epochs=epochs)\n",
        "    progress_bar = ProgressBar()\n",
        "    return [checkpoint, freezer, progress_bar]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2t8iJ38PRaE"
      },
      "source": [
        "# Trainer\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4bdyXZPOn7-"
      },
      "source": [
        "def get_accelerator():\n",
        "    tpu_device_exists = xla_device.XLADeviceUtils().tpu_device_exists()\n",
        "    has_gpu = cuda.is_available()\n",
        "\n",
        "    return {'tpu_cores': 8} if tpu_device_exists else \\\n",
        "           {'gpus': cuda.device_count()} if has_gpu else {}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jny1pcEGOpnN"
      },
      "source": [
        "max_epochs = 5\n",
        "production_mode = True\n",
        "\n",
        "def create_trainer(model_name, **kwargs):\n",
        "    callbacks = get_callbacks(model_name, max_epochs)\n",
        "    accelerator = get_accelerator()\n",
        "    return pl.Trainer(\n",
        "        max_epochs=max_epochs, deterministic=True, benchmark=True,\n",
        "        callbacks=callbacks, precision=16, **accelerator, **kwargs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kEzlvDeNF3q"
      },
      "source": [
        "# Tuning\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_e34IyRNHnU"
      },
      "source": [
        "def find_best_and_substitute_lr(model, **kwargs):\n",
        "    trainer = create_trainer(model.hparams.name, auto_lr_find=True, **kwargs)\n",
        "    if trainer.fast_dev_run:\n",
        "        return\n",
        "    lr_finder = trainer.tuner.lr_find(\n",
        "        model, early_stop_threshold=None, min_lr=1e-4, max_lr=9e-3,\n",
        "        datamodule=datamodule, num_training=100)\n",
        "    model.hparams.lr = lr_finder.suggestion()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCeMVuy-A4Ri"
      },
      "source": [
        "# Training and testing\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GFiyQOl-jZi"
      },
      "source": [
        "def create_fit_and_test(model_name, **kwargs):\n",
        "    model = PretrainedModel(model_name, max_epochs, STEPS)\n",
        "    find_best_and_substitute_lr(model, **kwargs)\n",
        "    print(f'Training with max lr of {model.hparams.lr:.2e}')\n",
        "    trainer = create_trainer(model.hparams.name, **kwargs)\n",
        "    trainer.fit(model, datamodule=datamodule)\n",
        "    trainer.test(model, datamodule=datamodule)\n",
        "    cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5llRfok5hhwZ"
      },
      "source": [
        "# Models results\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 814,
          "referenced_widgets": [
            "f700ce925181449c9b51d8b483b6fae0",
            "ea2b53dfe38e43a2b45dfafdba8cb2fc",
            "f8846514e4384c19a09aca60449dac2d",
            "c03b16509e394d7d9536270528cf323f",
            "bfd284648dd5450987e959b7d964a542",
            "aaeeedbc83524fd18ba917197ed2bb01",
            "7507a7233477476fac578ebd3a35255f",
            "c5e6d43c87994af0a9f8d72d46776473"
          ]
        },
        "id": "7IUetDolrkiD",
        "outputId": "58f51187-c538-49bc-c52a-d0d14057d263"
      },
      "source": [
        "create_fit_and_test('gernet_m')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU available: True, used: True\n",
            "TPU available: None, using: 0 TPU cores\n",
            "Using native 16bit precision.\n",
            "\n",
            "  | Name      | Type              | Params\n",
            "------------------------------------------------\n",
            "0 | model     | ByobNet           | 18.6 M\n",
            "1 | criterion | BCEWithLogitsLoss | 0     \n",
            "2 | metrics   | ModuleDict        | 0     \n",
            "------------------------------------------------\n",
            "2.6 K     Trainable params\n",
            "18.6 M    Non-trainable params\n",
            "18.6 M    Total params\n",
            "74.338    Total estimated model params size (MB)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f700ce925181449c9b51d8b483b6fae0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Finding best initial lr', style=ProgressStyle(descriptionâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Restored states from the checkpoint file at /content/lr_find_temp_model.ckpt\n",
            "GPU available: True, used: True\n",
            "TPU available: None, using: 0 TPU cores\n",
            "Using native 16bit precision.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training with max lr of 1.64e-04\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  | Name      | Type              | Params\n",
            "------------------------------------------------\n",
            "0 | model     | ByobNet           | 18.6 M\n",
            "1 | criterion | BCEWithLogitsLoss | 0     \n",
            "2 | metrics   | ModuleDict        | 0     \n",
            "------------------------------------------------\n",
            "2.6 K     Trainable params\n",
            "18.6 M    Non-trainable params\n",
            "18.6 M    Total params\n",
            "74.338    Total estimated model params size (MB)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0 - Time: 4.49e+5h - loss: nan.0 - v_num: 4 - val_loss: 0.683 - val_score: 0.425\n",
            "Start training\n",
            "Epoch: 0 - Time: 4.200m - loss: 0.121 - v_num: 4 - val_loss: 0.123 - val_score: 0.964 - train_loss: 0.084\n",
            "Epoch: 1 - Time: 4.560m - loss: 0.0524 - v_num: 4 - val_loss: 0.057 - val_score: 0.981 - train_loss: 0.0196\n",
            "Epoch: 2 - Time: 4.880m - loss: 0.0706 - v_num: 4 - val_loss: 0.0557 - val_score: 0.982 - train_loss: 0.0267\n",
            "Epoch: 3 - Time: 5.180m - loss: 0.0926 - v_num: 4 - val_loss: 0.0668 - val_score: 0.981 - train_loss: 0.137\n",
            "Epoch: 4 - Time: 5.760m - loss: 0.0621 - v_num: 4 - val_loss: 0.0411 - val_score: 0.990 - train_loss: 0.0121\n",
            "Total duration: 24.60m\n",
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{'test_acc': 0.8810408711433411,\n",
            " 'test_f1': 0.8547517657279968,\n",
            " 'test_loss': 0.2763727009296417,\n",
            " 'test_score': 0.867896318435669}\n",
            "--------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZfRQL75VVI2M"
      },
      "source": [
        "create_fit_and_test('repvgg_b0')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKeBxyitVglV"
      },
      "source": [
        "create_fit_and_test('rexnet_200')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fQ9TrlQV2PD"
      },
      "source": [
        "create_fit_and_test('tf_efficientnet_b4')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kerG8vMIuPie"
      },
      "source": [
        "# %load_ext tensorboard\n",
        "# %tensorboard --logdir /content/lightning_logs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QaZcJHqkfTYK"
      },
      "source": [
        "# !mv /content/lightning_logs /content/gdrive/MyDrive/Models/logs"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}