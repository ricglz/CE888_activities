{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Training.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "mUUtCI6-nJH5",
        "IKioRsqnkdCH",
        "Bu0y8g8gUmmz",
        "3XqUaGeNebYT",
        "iixFi55mUmm1",
        "81IxA3OC0PsK",
        "VPM2UAiV0cpL",
        "F961Gb0ZUmm3",
        "mCJL6DnTCrwK",
        "7UW7W-u0PXYy",
        "Kh9nEppHc2BG",
        "vCOLnxQePb1b",
        "i2t8iJ38PRaE",
        "2kEzlvDeNF3q",
        "bCeMVuy-A4Ri",
        "5llRfok5hhwZ"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python [default]",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f3ca32beeb7e4779b3a6461b4d582325": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5446bf8ab44340db8e62d954255bfc2f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6b48509dc74940fd88a0eec183f4fc35",
              "IPY_MODEL_7ee3e685d3e045b8aff1ad6c4a0412a1"
            ]
          }
        },
        "5446bf8ab44340db8e62d954255bfc2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6b48509dc74940fd88a0eec183f4fc35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e096834f062d470d9bca733d454795c5",
            "_dom_classes": [],
            "description": "Finding best initial lr:  99%",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 480,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 473,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d0b38c1932364c24a9ef4e356262d371"
          }
        },
        "7ee3e685d3e045b8aff1ad6c4a0412a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ca8e38e0aff645f48aae85609b99f070",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 473/480 [02:57&lt;00:02,  2.66it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0e74bcb551da4c7082567c0e7bb570cc"
          }
        },
        "e096834f062d470d9bca733d454795c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d0b38c1932364c24a9ef4e356262d371": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ca8e38e0aff645f48aae85609b99f070": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0e74bcb551da4c7082567c0e7bb570cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ricglz/CE888_activities/blob/version_2/assignment/Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUUtCI6-nJH5"
      },
      "source": [
        "# Normally constant aspects (doesn't require as much config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKioRsqnkdCH"
      },
      "source": [
        "## Install dependencies\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jR0i3ECTUmmx"
      },
      "source": [
        "!pip --quiet install torch torchvision patool timm pytorch-lightning"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lfg7Kyt4i7Av"
      },
      "source": [
        "from math import ceil\n",
        "from os import path, mkdir\n",
        "from pandas import DataFrame\n",
        "from patoolib import extract_archive\n",
        "from sklearn.model_selection import train_test_split\n",
        "from time import time\n",
        "from tqdm import tqdm\n",
        "from zipfile import ZipFile\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import seaborn as sns\n",
        "import sys\n",
        "import timm\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "import pytorch_lightning.callbacks as pl_callbacks\n",
        "from pytorch_lightning.utilities import xla_device\n",
        "from pytorch_lightning.loggers import TensorBoardLogger\n",
        "from pytorch_lightning.metrics import Accuracy, ConfusionMatrix, \\\n",
        "                                      MetricCollection, F1\n",
        "\n",
        "from torch import cuda, sigmoid, stack, use_deterministic_algorithms\n",
        "from torch.nn import BCEWithLogitsLoss, ModuleDict\n",
        "from torch.nn.modules.batchnorm import _BatchNorm\n",
        "from torch.optim import Adam, AdamW, RMSprop, SGD\n",
        "from torch.optim.lr_scheduler import OneCycleLR\n",
        "from torch.utils.data import DataLoader, Dataset, Subset, random_split\n",
        "from torch.utils.data.sampler import Sampler\n",
        "\n",
        "import torchvision.transforms as T\n",
        "from torchvision.datasets import ImageFolder"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bu0y8g8gUmmz"
      },
      "source": [
        "## Data setup\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4p6zCFXskagK"
      },
      "source": [
        "\n",
        "Before we begin, lets mount the google drive to later on read information from it:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NeqA16HnUmmz"
      },
      "source": [
        "try:\n",
        "    from google.colab import drive\n",
        "    in_colab = True\n",
        "except ImportError:\n",
        "    in_colab = False"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjDGpTDvu_Dl"
      },
      "source": [
        "def unzip_file(zip_path, dest_path):\n",
        "    with ZipFile(zip_path, 'r') as zf:\n",
        "        for member in tqdm(zf.infolist(), desc='Extracting '):\n",
        "            zf.extract(member, dest_path)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NE6t24_MdGq"
      },
      "source": [
        "def unrar_files(tar_dir_path, dest_dir):\n",
        "    if not path.exists(dest_dir):\n",
        "        mkdir(dest_dir)\n",
        "    for dataset in ('Test', 'Training'):\n",
        "        tar_path = path.join(tar_dir_path, f'{dataset}.tar')\n",
        "        dest_folder = path.join(dest_dir, dataset)\n",
        "        if path.exists(dest_folder):\n",
        "            continue\n",
        "        mkdir(dest_folder)\n",
        "        extract_archive(tar_path, outdir=dest_folder)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a79Zqbf0pM4Y"
      },
      "source": [
        "minified = True"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7vrQkuNvBrE"
      },
      "source": [
        "def get_data_dir():\n",
        "    kaggle_path = '../input/ce888-dataset'\n",
        "    if path.exists(kaggle_path):\n",
        "        dest_dir = './data'\n",
        "        unrar_files(kaggle_path, dest_dir)\n",
        "        return dest_dir\n",
        "\n",
        "    general_dir = '.'\n",
        "    data_dir = general_dir + '/Flame'\n",
        "    if in_colab and not path.exists(data_dir):\n",
        "        drive_path = '/content/gdrive'\n",
        "        drive.mount(drive_path, force_remount=False)\n",
        "        zip_file = 'Minified-Flame.zip' if minified else 'Flame.zip'\n",
        "        zip_path = f'MyDrive/Essex/Datasets/zipped/{zip_file}'\n",
        "        unzip_file(path.join(drive_path, zip_path), general_dir)\n",
        "    return data_dir"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3P1wZc3yjqD"
      },
      "source": [
        "def get_model_dir():\n",
        "    return './Models'\n",
        "    return '/content/gdrive/MyDrive/Models/Lightning' if in_colab \\\n",
        "           else './Models'"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3XqUaGeNebYT"
      },
      "source": [
        "## Seed\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuutjrXRcWd7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a67bc546-c79c-4117-8a47-2e016a899763"
      },
      "source": [
        "seed = 42\n",
        "pl.seed_everything(seed)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Global seed set to 42\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "42"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iixFi55mUmm1"
      },
      "source": [
        "## Datamodule preparation\n",
        "\n",
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TqYrYNWAQ18"
      },
      "source": [
        "A datamodule is a module that provides us _lightning_ to be able to structure our datadependencies in a more modular way\n",
        "\n",
        "In this case we will also declare transformations like the resize and the normalization. The normalization used are [the mean and std of the ImageNet dataset](https://github.com/rwightman/pytorch-image-models/blob/master/timm/data/constants.py)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81IxA3OC0PsK"
      },
      "source": [
        "### Helper classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdglgiCQNCUK"
      },
      "source": [
        "class BalancedBatchSampler(Sampler):\n",
        "    \"\"\"\n",
        "    Inspired by:\n",
        "    https://github.com/galatolofederico/pytorch-balanced-batch/blob/master/sampler.py\n",
        "    \"\"\"\n",
        "    def __init__(self, dataset, shuffle=False):\n",
        "        super().__init__(None)\n",
        "        self.dataset = dict()\n",
        "        real_dataset = dataset\n",
        "        while hasattr(real_dataset, 'dataset'):\n",
        "            real_dataset = real_dataset.dataset\n",
        "        self.balanced_max = 0\n",
        "        self.shuffle = shuffle\n",
        "        # Save all the indices for all the classes\n",
        "        for idx in range(0, len(dataset)):\n",
        "            label = self._get_label(real_dataset, idx)\n",
        "            if label not in self.dataset:\n",
        "                self.dataset[label] = list()\n",
        "            self.dataset[label].append(idx)\n",
        "            self.balanced_max = max(len(self.dataset[label]), self.balanced_max)\n",
        "\n",
        "        # Oversample the classes with fewer elements than the max\n",
        "        for label in self.dataset:\n",
        "            while len(self.dataset[label]) < self.balanced_max:\n",
        "                self.dataset[label].append(random.choice(self.dataset[label]))\n",
        "        self.keys = list(self.dataset.keys())\n",
        "        self.current_key = 0\n",
        "        self.indices = [-1]*len(self.keys)\n",
        "\n",
        "    @staticmethod\n",
        "    def _get_label(dataset, idx):\n",
        "        return dataset.imgs[idx][1]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.balanced_max*len(self.keys)\n",
        "\n",
        "    def __iter__(self):\n",
        "        if self.shuffle:\n",
        "            for key in self.keys:\n",
        "                random.shuffle(self.dataset[key])\n",
        "        while self.indices[self.current_key] < self.balanced_max - 1:\n",
        "            self.indices[self.current_key] += 1\n",
        "            label = self.keys[self.current_key]\n",
        "            index_label = self.indices[self.current_key]\n",
        "            yield self.dataset[label][index_label]\n",
        "            self.current_key = (self.current_key + 1) % len(self.keys)\n",
        "        self.indices = [-1]*len(self.keys)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPM2UAiV0cpL"
      },
      "source": [
        "### DataModule"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXy9kHAN8JV0"
      },
      "source": [
        "DEFAULT_BATCH_SIZE = 32\n",
        "DEFAULT_IMAGE_SIZE = (224, 224)\n",
        "STEPS = 1198 if minified else 2397\n",
        "\n",
        "class FlameDataModule(pl.LightningDataModule):\n",
        "    def __init__(\n",
        "            self,\n",
        "            batch_size=DEFAULT_BATCH_SIZE,\n",
        "            image_size=DEFAULT_IMAGE_SIZE\n",
        "        ):\n",
        "        super().__init__()\n",
        "        self.batch_size = batch_size\n",
        "        resize = T.Resize(image_size)\n",
        "        normalize = T.Normalize([0.485, 0.456, 0.406], \n",
        "                                [0.229, 0.224, 0.225])\n",
        "        toTensor = T.ToTensor()\n",
        "        self.train_transforms = T.Compose([\n",
        "            resize,\n",
        "            T.ColorJitter(brightness=0.1, contrast=0.1),\n",
        "            T.RandomRotation(degrees=45),\n",
        "            T.RandomHorizontalFlip(),\n",
        "            T.RandomVerticalFlip(),\n",
        "            toTensor,\n",
        "            normalize\n",
        "        ])\n",
        "        self.transforms = T.Compose([resize, toTensor, normalize])\n",
        "\n",
        "    def prepare_data(self):\n",
        "        self.data_dir = get_data_dir()\n",
        "    \n",
        "    def create_dataset(self, folder_name, transforms):\n",
        "        return ImageFolder(path.join(self.data_dir, folder_name), transforms)\n",
        "\n",
        "    def setup(self, stage=None):\n",
        "        if stage == 'fit' or stage is None:\n",
        "            self.train_ds = self.create_dataset('Training', self.train_transforms)\n",
        "            self.val_ds = self.create_dataset('Validation', self.transforms)\n",
        "        if stage == 'test' or stage is None:\n",
        "            self.test_ds = self.create_dataset('Test', self.transforms)\n",
        "\n",
        "    def _general_dataloader(self, dataset, **kwargs):\n",
        "        return DataLoader(\n",
        "            dataset, batch_size=self.batch_size, num_workers=2, drop_last=True,\n",
        "            pin_memory=True, **kwargs)\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        sampler = BalancedBatchSampler(self.train_ds, shuffle=True)\n",
        "        return self._general_dataloader(self.train_ds, sampler=sampler)\n",
        "        # print(len(loader))\n",
        "        # return loader\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return self._general_dataloader(self.val_ds)\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return self._general_dataloader(self.test_ds)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJCidcqFNrfU"
      },
      "source": [
        "datamodule = FlameDataModule()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F961Gb0ZUmm3"
      },
      "source": [
        "# Model \n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cd7xePlvUmm4"
      },
      "source": [
        "class PretrainedModel(pl.LightningModule):\n",
        "    def __init__(\n",
        "        self, name='rexnet_200', epochs=10, steps_per_epoch=100, lr=1e-3,\n",
        "        drop_rate=0.5, max_momentum=0.95\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.save_hyperparameters()\n",
        "        self.model = timm.create_model(name, pretrained=True,\n",
        "                                       num_classes=1, drop_rate=drop_rate)\n",
        "        self.just_train_classifier()\n",
        "\n",
        "        self.criterion = BCEWithLogitsLoss()\n",
        "        self.metrics = self.build_metrics()\n",
        "        self.transform = T.Compose([\n",
        "            T.RandomHorizontalFlip(),\n",
        "            T.RandomVerticalFlip()\n",
        "        ])\n",
        "    \n",
        "    def just_train_classifier(self):\n",
        "        self.freeze()\n",
        "        Freezer.make_trainable(self.model.get_classifier())\n",
        "\n",
        "    @staticmethod\n",
        "    def build_metrics():\n",
        "        general_metrics = [\n",
        "            Accuracy(compute_on_step=False),\n",
        "            F1(num_classes=2, compute_on_step=False)\n",
        "        ]\n",
        "        metric = MetricCollection(general_metrics)\n",
        "        return ModuleDict({\n",
        "            'test_metrics': metric.clone(),\n",
        "            'train_metrics': metric.clone(),\n",
        "            'val_metrics': metric.clone(),\n",
        "        })\n",
        "\n",
        "    def forward(self, x, tta = 0):\n",
        "        if tta == 0:\n",
        "            return self.model(x).squeeze(-1)\n",
        "        y_hat_stack = stack([self(self.transform(x)) for _ in range(tta)])\n",
        "        return y_hat_stack.mean(dim=0)\n",
        "    \n",
        "    def predict(self, x):\n",
        "        proba = sigmoid(self(x))\n",
        "        return (proba > 0.5).byte()\n",
        "\n",
        "    # Configurations\n",
        "    def configure_optimizers(self):\n",
        "        parameters = filter(lambda p: p.requires_grad, self.parameters())\n",
        "        optimizer = Adam(parameters, self.hparams.lr, weight_decay=1e-2)\n",
        "        # optimizer = Lookahead(optimizer)\n",
        "        scheduler = self._build_scheduler(optimizer)\n",
        "        scheduler_dict = {'scheduler': scheduler, 'interval': 'step'}\n",
        "        return [optimizer], [scheduler_dict]\n",
        "    \n",
        "    def _build_scheduler(self, optimizer):\n",
        "        lr, epochs = self.hparams.lr, self.hparams.epochs\n",
        "        max_momentum = self.hparams.max_momentum\n",
        "        base_momentum = max_momentum - 0.1\n",
        "        total_steps = epochs * self.hparams.steps_per_epoch\n",
        "        div_factor = epochs * 4\n",
        "        return OneCycleLR(\n",
        "            optimizer, lr, total_steps, pct_start=0.55, div_factor=div_factor,\n",
        "            final_div_factor=div_factor, three_phase=True,\n",
        "            max_momentum=max_momentum, base_momentum=base_momentum)\n",
        "\n",
        "    # Steps\n",
        "    def _get_dataset_metrics(self, dataset):\n",
        "        return self.metrics[f'{dataset}_metrics']\n",
        "\n",
        "    def _update_metrics(self, y_hat, y, dataset):\n",
        "        proba = sigmoid(y_hat)\n",
        "        self._get_dataset_metrics(dataset).update(proba, y)\n",
        "\n",
        "    def _on_step(self, batch, dataset):\n",
        "        x, y = batch\n",
        "        tta = 10 if dataset == 'test' else 0\n",
        "        y_hat = self(x, tta)\n",
        "        loss = self.criterion(y_hat, y.float())\n",
        "        self._update_metrics(y_hat, y, dataset)\n",
        "        self.log(f'{dataset}_loss', loss, prog_bar=True)\n",
        "        return loss\n",
        "\n",
        "    def _on_end_epochs(self, outputs, dataset):\n",
        "        labels = [f'{dataset}_acc', f'{dataset}_f1']\n",
        "        metrics = self._get_dataset_metrics(dataset)\n",
        "        metrics_values = metrics.compute().values()\n",
        "        for label, value in zip(labels, metrics_values):\n",
        "            self.log(label, value)\n",
        "        if dataset != 'train':\n",
        "            score = stack(list(metrics_values)).mean()\n",
        "            self.log(f'{dataset}_score', score, prog_bar=True)\n",
        "        metrics.reset()\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        return self._on_step(batch, 'train')\n",
        "    \n",
        "    def training_epoch_end(self, outputs):\n",
        "        self._on_end_epochs(outputs, 'train')\n",
        "    \n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        return self._on_step(batch, 'val')\n",
        "\n",
        "    def validation_epoch_end(self, outputs):\n",
        "        self._on_end_epochs(outputs, 'val')\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        return self._on_step(batch, 'test')\n",
        "\n",
        "    def test_epoch_end(self, outputs):\n",
        "        self._on_end_epochs(outputs, 'test')"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCJL6DnTCrwK"
      },
      "source": [
        "# Callbacks\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7UW7W-u0PXYy"
      },
      "source": [
        "## Freezer class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnP01wWyD60E"
      },
      "source": [
        "class Freezer(pl_callbacks.BaseFinetuning):\n",
        "    trainable_layers = []\n",
        "\n",
        "    def __init__(\n",
        "        self, steps=4, unfreeze_per_step=8, train_bn=False, epochs=40\n",
        "    ):\n",
        "        self.step_size = ceil(epochs / (steps + 1))\n",
        "        self.unfreeze_per_step = unfreeze_per_step\n",
        "        self.train_bn = train_bn\n",
        "\n",
        "    @staticmethod\n",
        "    def flatten_children(module):\n",
        "        vanilla_children = list(module.children())\n",
        "        if len(vanilla_children) == 0:\n",
        "            return [module]\n",
        "        children = []\n",
        "        for child in vanilla_children:\n",
        "            child_children = Freezer.flatten_children(child)\n",
        "            children += child_children\n",
        "        return children\n",
        "\n",
        "    @staticmethod\n",
        "    def filter_non_trainable(children):\n",
        "        calc_num_params = lambda module: sum(p.numel() for p in module.parameters())\n",
        "        has_params = lambda module: calc_num_params(module) > 0\n",
        "        return list(filter(has_params, children))\n",
        "    \n",
        "    @staticmethod\n",
        "    def filter_non_frozen(children):\n",
        "        requires_grad = lambda p: p.requires_grad\n",
        "        is_frozen_module = \\\n",
        "            lambda module: len(list(filter(requires_grad, module.parameters()))) == 0\n",
        "        return list(filter(is_frozen_module, children))\n",
        "\n",
        "    @staticmethod\n",
        "    def trainable_children(pl_module, train_bn=False, reverse=False):\n",
        "        children = Freezer.flatten_children(pl_module)\n",
        "        children = Freezer.filter_non_trainable(children)\n",
        "        children = Freezer.filter_non_frozen(children)\n",
        "        if not train_bn:\n",
        "            is_not_bn = lambda mod: not isinstance(mod, _BatchNorm) \n",
        "            children = list(filter(is_not_bn, children))\n",
        "        if reverse:\n",
        "            children.reverse()\n",
        "        return children\n",
        "    \n",
        "    def freeze_before_training(self, pl_module):\n",
        "        self.trainable_layers = self.trainable_children(\n",
        "            pl_module, self.train_bn, reverse=True)\n",
        "    \n",
        "    def finetune_function(self, pl_module, current_epoch, optimizer, optimizer_idx):\n",
        "        trainable_layers_len = len(self.trainable_layers)\n",
        "        is_empty = trainable_layers_len == 0\n",
        "        is_finetune_epoch = current_epoch % self.step_size == 0 and \\\n",
        "                         current_epoch != 0\n",
        "        if not is_finetune_epoch or is_empty:\n",
        "            return\n",
        "        to_be_trained_layers = []\n",
        "        layers_to_be_freeze = min(self.unfreeze_per_step, trainable_layers_len)\n",
        "        for _ in range(layers_to_be_freeze):\n",
        "            to_be_trained_layers.append(self.trainable_layers.pop(0))\n",
        "        self.unfreeze_and_add_param_group(\n",
        "            to_be_trained_layers, optimizer, swa=True, one_cycle=True)\n",
        "\n",
        "    @staticmethod\n",
        "    def unfreeze_and_add_param_group(\n",
        "        modules,\n",
        "        optimizer,\n",
        "        swa = False,\n",
        "        one_cycle = False,\n",
        "        lr = None,\n",
        "        initial_denom_lr = 10.,\n",
        "        train_bn = True,\n",
        "    ):\n",
        "        Freezer.make_trainable(modules)\n",
        "        params_lr = optimizer.param_groups[0]['lr'] if lr is None else float(lr)\n",
        "        denom_lr = initial_denom_lr if lr is None else 1.\n",
        "        initial_lr = params_lr / denom_lr\n",
        "        params = Freezer.filter_params(modules, train_bn=train_bn, requires_grad=True)\n",
        "        params = Freezer.filter_on_optimizer(optimizer, params)\n",
        "        if params:\n",
        "            param_group = {\n",
        "                'params': params, 'lr': initial_lr, 'initial_lr': initial_lr,\n",
        "            }\n",
        "            extra_data = {}\n",
        "            if one_cycle:\n",
        "                extra_data = Freezer.momentum_param_group(optimizer)\n",
        "            if swa:\n",
        "                extra_data = { 'swa_lr': initial_lr, **extra_data }\n",
        "            param_group = { **param_group, **extra_data }\n",
        "            optimizer.add_param_group(param_group)\n",
        "\n",
        "    @staticmethod\n",
        "    def momentum_param_group(optimizer):\n",
        "        group = optimizer.param_groups[0]\n",
        "        momentum_group = {\n",
        "            'base_momentum': group['base_momentum'],\n",
        "            'max_momentum': group['max_momentum'],\n",
        "            'max_lr': group['max_lr'],\n",
        "            'min_lr': group['min_lr'],\n",
        "        }\n",
        "        extra_group = {\n",
        "            'betas': group['betas']\n",
        "        } if 'betas' in optimizer.defaults else {\n",
        "            'momentum': group['momentum']\n",
        "        }\n",
        "        return { **momentum_group, **extra_group }"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kh9nEppHc2BG"
      },
      "source": [
        "## ProgressBar class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rV6ZiB0nc1Wk"
      },
      "source": [
        "class ProgressBar(pl_callbacks.ProgressBarBase):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.epoch_time = 0\n",
        "        self.stage_time = 0\n",
        "    \n",
        "    def disable(self):\n",
        "        pass\n",
        "    \n",
        "    def enable(self):\n",
        "        pass\n",
        "\n",
        "    @staticmethod\n",
        "    def format_num(n) -> str:\n",
        "        \"\"\" Add additional padding to the formatted numbers \"\"\"\n",
        "        should_be_padded = isinstance(n, (float, str))\n",
        "        if not isinstance(n, str):\n",
        "            n = tqdm.format_num(n)\n",
        "        if should_be_padded and 'e' not in n:\n",
        "            if '.' not in n and len(n) < 5:\n",
        "                try:\n",
        "                    _ = float(n)\n",
        "                except ValueError:\n",
        "                    return n\n",
        "                n += '.'\n",
        "            n += \"0\" * (5 - len(n))\n",
        "        return n\n",
        "    \n",
        "    def get_formatted_duration(self, prev_time):\n",
        "        duration = time() - prev_time\n",
        "        if duration < 60:\n",
        "            unit = 's'\n",
        "        elif duration < 3600:\n",
        "            duration /= 60\n",
        "            unit = 'm'\n",
        "        else:\n",
        "            duration /= 3600\n",
        "            unit = 'h'\n",
        "        return self.format_num(duration) + unit\n",
        "    \n",
        "    def on_train_start(self, trainer, pl_module):\n",
        "        self.stage_time = time()\n",
        "        print('Start training')\n",
        "\n",
        "    def on_train_end(self, trainer, pl_module):\n",
        "        print(f'Total duration: {self.get_formatted_duration(self.stage_time)}')\n",
        "    \n",
        "    def on_train_epoch_start(self, trainer, pl_module):\n",
        "        self.epoch_time = time()\n",
        "    \n",
        "    def on_validation_epoch_end(self, trainer, pl_module):\n",
        "        values = [\n",
        "            f'Epoch: {trainer.current_epoch}',\n",
        "            f'Time: {self.get_formatted_duration(self.epoch_time)}'\n",
        "        ]\n",
        "        values += [\n",
        "            f'{key}: {self.format_num(value)}'\n",
        "            for key, value in trainer.progress_bar_dict.items()\n",
        "        ]\n",
        "        print(' - '.join(values))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCOLnxQePb1b"
      },
      "source": [
        "## Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57HupS7lBJ4C"
      },
      "source": [
        "def get_checkpoint(model_name):\n",
        "    filename = '{epoch:02d}-{val_score:.4f}'\n",
        "    production_dirpath = path.join(get_model_dir(), model_name)\n",
        "    dirpath = production_dirpath if production_mode else model_name\n",
        "    return pl_callbacks.ModelCheckpoint(\n",
        "        dirpath=dirpath, monitor='val_score', mode='max', filename=filename)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StGH-GbjA99v"
      },
      "source": [
        "def get_callbacks(model_name, epochs):\n",
        "    checkpoint = get_checkpoint(model_name)\n",
        "    freezer = Freezer(epochs=epochs)\n",
        "    progress_bar = ProgressBar()\n",
        "    return [checkpoint, freezer, progress_bar]"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2t8iJ38PRaE"
      },
      "source": [
        "# Trainer\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4bdyXZPOn7-"
      },
      "source": [
        "def get_accelerator():\n",
        "    tpu_device_exists = xla_device.XLADeviceUtils().tpu_device_exists()\n",
        "    has_gpu = cuda.is_available()\n",
        "\n",
        "    return {'tpu_cores': 8} if tpu_device_exists else \\\n",
        "           {'gpus': cuda.device_count()} if has_gpu else {}"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jny1pcEGOpnN"
      },
      "source": [
        "max_epochs = 5\n",
        "production_mode = True\n",
        "\n",
        "def create_trainer(model_name, **kwargs):\n",
        "    callbacks = get_callbacks(model_name, max_epochs)\n",
        "    accelerator = get_accelerator()\n",
        "    return pl.Trainer(\n",
        "        max_epochs=max_epochs, deterministic=True, benchmark=True,\n",
        "        callbacks=callbacks, precision=16, stochastic_weight_avg=False,\n",
        "        **accelerator, **kwargs)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kEzlvDeNF3q"
      },
      "source": [
        "# Tuning\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_e34IyRNHnU"
      },
      "source": [
        "def find_best_and_substitute_lr(model, **kwargs):\n",
        "    trainer = create_trainer(model.hparams.name, auto_lr_find=True, **kwargs)\n",
        "    if trainer.fast_dev_run:\n",
        "        return\n",
        "    lr_finder = trainer.tuner.lr_find(\n",
        "        model, datamodule=datamodule, num_training=480)\n",
        "    lr_finder.plot(suggest=True, show=True)\n",
        "    suggest_lr = lr_finder.results['lr'][lr_finder._optimal_idx]\n",
        "    model.hparams.lr = suggest_lr"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCeMVuy-A4Ri"
      },
      "source": [
        "# Training and testing\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GFiyQOl-jZi"
      },
      "source": [
        "def create_fit_and_test(model_name, **kwargs):\n",
        "    model = PretrainedModel(model_name, max_epochs, STEPS)\n",
        "    find_best_and_substitute_lr(model, **kwargs)\n",
        "    print(f'Training with max lr of {model.hparams.lr:.2e}')\n",
        "    trainer = create_trainer(model.hparams.name, **kwargs)\n",
        "    trainer.fit(model, datamodule=datamodule)\n",
        "    trainer.test(model, datamodule=datamodule)\n",
        "    cuda.empty_cache()"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5llRfok5hhwZ"
      },
      "source": [
        "# Models results\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IUetDolrkiD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "f3ca32beeb7e4779b3a6461b4d582325",
            "5446bf8ab44340db8e62d954255bfc2f",
            "6b48509dc74940fd88a0eec183f4fc35",
            "7ee3e685d3e045b8aff1ad6c4a0412a1",
            "e096834f062d470d9bca733d454795c5",
            "d0b38c1932364c24a9ef4e356262d371",
            "ca8e38e0aff645f48aae85609b99f070",
            "0e74bcb551da4c7082567c0e7bb570cc"
          ]
        },
        "outputId": "e66df284-3b60-4896-a81a-1bc6f4148f69"
      },
      "source": [
        "create_fit_and_test('gernet_m')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU available: True, used: True\n",
            "TPU available: None, using: 0 TPU cores\n",
            "Using native 16bit precision.\n",
            "\n",
            "  | Name      | Type              | Params\n",
            "------------------------------------------------\n",
            "0 | model     | ByobNet           | 18.6 M\n",
            "1 | criterion | BCEWithLogitsLoss | 0     \n",
            "2 | metrics   | ModuleDict        | 0     \n",
            "------------------------------------------------\n",
            "2.6 K     Trainable params\n",
            "18.6 M    Non-trainable params\n",
            "18.6 M    Total params\n",
            "74.338    Total estimated model params size (MB)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f3ca32beeb7e4779b3a6461b4d582325",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Finding best initial lr', max=480.0, style=ProgressStyle(…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "LR finder stopped early due to diverging loss.\n",
            "Restored states from the checkpoint file at /content/lr_find_temp_model.ckpt\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "GPU available: True, used: True\n",
            "TPU available: None, using: 0 TPU cores\n",
            "Using native 16bit precision.\n",
            "\n",
            "  | Name      | Type              | Params\n",
            "------------------------------------------------\n",
            "0 | model     | ByobNet           | 18.6 M\n",
            "1 | criterion | BCEWithLogitsLoss | 0     \n",
            "2 | metrics   | ModuleDict        | 0     \n",
            "------------------------------------------------\n",
            "2.6 K     Trainable params\n",
            "18.6 M    Non-trainable params\n",
            "18.6 M    Total params\n",
            "74.338    Total estimated model params size (MB)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training with max lr of 2.93e-03\n",
            "Epoch: 0 - Time: 4.49e+5h - loss: nan.0 - v_num: 7 - val_loss: 0.700 - val_score: 0.297\n",
            "Start training\n",
            "Epoch: 0 - Time: 2.280m - loss: 0.192 - v_num: 7 - val_loss: 0.187 - val_score: 0.946 - train_loss: 0.136\n",
            "Epoch: 1 - Time: 2.310m - loss: 0.212 - v_num: 7 - val_loss: 0.177 - val_score: 0.938 - train_loss: 0.128\n",
            "Epoch: 2 - Time: 2.360m - loss: 0.139 - v_num: 7 - val_loss: 0.137 - val_score: 0.959 - train_loss: 0.319\n",
            "Epoch: 3 - Time: 2.410m - loss: 0.121 - v_num: 7 - val_loss: 0.159 - val_score: 0.943 - train_loss: 0.144\n",
            "Epoch: 4 - Time: 2.440m - loss: 0.120 - v_num: 7 - val_loss: 0.127 - val_score: 0.952 - train_loss: 0.154\n",
            "Total duration: 11.80m\n",
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{'test_acc': 0.8042518496513367,\n",
            " 'test_f1': 0.7812540531158447,\n",
            " 'test_loss': 0.43756604194641113,\n",
            " 'test_score': 0.7927529811859131}\n",
            "--------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZfRQL75VVI2M"
      },
      "source": [
        "create_fit_and_test('repvgg_b0')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKeBxyitVglV"
      },
      "source": [
        "create_fit_and_test('rexnet_200')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fQ9TrlQV2PD"
      },
      "source": [
        "create_fit_and_test('tf_efficientnet_b4')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kerG8vMIuPie"
      },
      "source": [
        "# %load_ext tensorboard\n",
        "# %tensorboard --logdir /content/lightning_logs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QaZcJHqkfTYK"
      },
      "source": [
        "# !mv /content/lightning_logs /content/gdrive/MyDrive/Models/logs"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}