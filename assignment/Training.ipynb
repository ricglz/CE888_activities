{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Training.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "mUUtCI6-nJH5",
        "IKioRsqnkdCH",
        "Bu0y8g8gUmmz",
        "3XqUaGeNebYT",
        "iixFi55mUmm1",
        "81IxA3OC0PsK",
        "VPM2UAiV0cpL",
        "F961Gb0ZUmm3",
        "mCJL6DnTCrwK",
        "7UW7W-u0PXYy",
        "Kh9nEppHc2BG",
        "vCOLnxQePb1b",
        "i2t8iJ38PRaE",
        "2kEzlvDeNF3q",
        "bCeMVuy-A4Ri",
        "5llRfok5hhwZ"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python [default]",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ff3380b109fa42a38cb66e8fe69c813a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_847a40bc4fcc45c8943a7fc464d28adb",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_bca94177645b4c57bff6aadafcad9600",
              "IPY_MODEL_16030d92526a4294aa56b4bd67ade72f"
            ]
          }
        },
        "847a40bc4fcc45c8943a7fc464d28adb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bca94177645b4c57bff6aadafcad9600": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5b135056553745859b4c431c42e1a8a1",
            "_dom_classes": [],
            "description": "Finding best initial lr: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 400,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 400,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_77d8cdf0742f4cda9ffb92b8c5c970ef"
          }
        },
        "16030d92526a4294aa56b4bd67ade72f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_867db44fed064babaee4eb978d8caabd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 400/400 [00:50&lt;00:00,  7.59it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3f1847058e394cb1b6d83fba63facd03"
          }
        },
        "5b135056553745859b4c431c42e1a8a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "77d8cdf0742f4cda9ffb92b8c5c970ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "867db44fed064babaee4eb978d8caabd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3f1847058e394cb1b6d83fba63facd03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ricglz/CE888_activities/blob/version_2/assignment/Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUUtCI6-nJH5"
      },
      "source": [
        "# Normally constant aspects (doesn't require as much config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKioRsqnkdCH"
      },
      "source": [
        "## Install dependencies\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jR0i3ECTUmmx"
      },
      "source": [
        "!pip --quiet install torch torchvision patool timm pytorch-lightning"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lfg7Kyt4i7Av"
      },
      "source": [
        "from math import ceil\n",
        "from os import path, mkdir\n",
        "from pandas import DataFrame\n",
        "from patoolib import extract_archive\n",
        "from sklearn.model_selection import train_test_split\n",
        "from time import time\n",
        "from tqdm import tqdm\n",
        "from zipfile import ZipFile\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import seaborn as sns\n",
        "import sys\n",
        "import timm\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "import pytorch_lightning.callbacks as pl_callbacks\n",
        "from pytorch_lightning.utilities import xla_device\n",
        "from pytorch_lightning.loggers import TensorBoardLogger\n",
        "from pytorch_lightning.metrics import Accuracy, ConfusionMatrix, \\\n",
        "                                      MetricCollection, F1\n",
        "\n",
        "from torch import cuda, sigmoid, stack, use_deterministic_algorithms\n",
        "from torch.nn import BCEWithLogitsLoss, ModuleDict\n",
        "from torch.nn.modules.batchnorm import _BatchNorm\n",
        "from torch.optim import Adam, AdamW, RMSprop, SGD\n",
        "from torch.optim.lr_scheduler import OneCycleLR\n",
        "from torch.utils.data import DataLoader, Dataset, Subset, random_split\n",
        "from torch.utils.data.sampler import Sampler\n",
        "\n",
        "import torchvision.transforms as T\n",
        "from torchvision.datasets import ImageFolder"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bu0y8g8gUmmz"
      },
      "source": [
        "## Data setup\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4p6zCFXskagK"
      },
      "source": [
        "\n",
        "Before we begin, lets mount the google drive to later on read information from it:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NeqA16HnUmmz"
      },
      "source": [
        "try:\n",
        "    from google.colab import drive\n",
        "    in_colab = True\n",
        "except ImportError:\n",
        "    in_colab = False"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjDGpTDvu_Dl"
      },
      "source": [
        "def unzip_file(zip_path, dest_path):\n",
        "    with ZipFile(zip_path, 'r') as zf:\n",
        "        for member in tqdm(zf.infolist(), desc='Extracting '):\n",
        "            zf.extract(member, dest_path)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NE6t24_MdGq"
      },
      "source": [
        "def unrar_files(tar_dir_path, dest_dir):\n",
        "    if not path.exists(dest_dir):\n",
        "        mkdir(dest_dir)\n",
        "    for dataset in ('Test', 'Training'):\n",
        "        tar_path = path.join(tar_dir_path, f'{dataset}.tar')\n",
        "        dest_folder = path.join(dest_dir, dataset)\n",
        "        if path.exists(dest_folder):\n",
        "            continue\n",
        "        mkdir(dest_folder)\n",
        "        extract_archive(tar_path, outdir=dest_folder)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a79Zqbf0pM4Y"
      },
      "source": [
        "minified = True"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7vrQkuNvBrE"
      },
      "source": [
        "def get_data_dir():\n",
        "    kaggle_path = '../input/ce888-dataset'\n",
        "    if path.exists(kaggle_path):\n",
        "        dest_dir = './data'\n",
        "        unrar_files(kaggle_path, dest_dir)\n",
        "        return dest_dir\n",
        "\n",
        "    general_dir = '.'\n",
        "    data_dir = general_dir + '/Flame'\n",
        "    if in_colab and not path.exists(data_dir):\n",
        "        drive_path = '/content/gdrive'\n",
        "        drive.mount(drive_path, force_remount=False)\n",
        "        zip_file = 'Minified-Flame.zip' if minified else 'Flame.zip'\n",
        "        zip_path = f'MyDrive/Essex/Datasets/zipped/{zip_file}'\n",
        "        unzip_file(path.join(drive_path, zip_path), general_dir)\n",
        "    return data_dir"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3P1wZc3yjqD"
      },
      "source": [
        "def get_model_dir():\n",
        "    return './Models'\n",
        "    return '/content/gdrive/MyDrive/Models/Lightning' if in_colab \\\n",
        "           else './Models'"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3XqUaGeNebYT"
      },
      "source": [
        "## Seed\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuutjrXRcWd7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eff0df7c-c498-4e51-cb60-218122cd3514"
      },
      "source": [
        "seed = 42\n",
        "pl.seed_everything(seed)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Global seed set to 42\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "42"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iixFi55mUmm1"
      },
      "source": [
        "## Datamodule preparation\n",
        "\n",
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TqYrYNWAQ18"
      },
      "source": [
        "A datamodule is a module that provides us _lightning_ to be able to structure our datadependencies in a more modular way\n",
        "\n",
        "In this case we will also declare transformations like the resize and the normalization. The normalization used are [the mean and std of the ImageNet dataset](https://github.com/rwightman/pytorch-image-models/blob/master/timm/data/constants.py)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81IxA3OC0PsK"
      },
      "source": [
        "### Helper classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdglgiCQNCUK"
      },
      "source": [
        "class BalancedBatchSampler(Sampler):\n",
        "    \"\"\"\n",
        "    Inspired by:\n",
        "    https://github.com/galatolofederico/pytorch-balanced-batch/blob/master/sampler.py\n",
        "    \"\"\"\n",
        "    def __init__(self, dataset, shuffle=False):\n",
        "        super().__init__(None)\n",
        "        self.dataset = dict()\n",
        "        real_dataset = dataset\n",
        "        while hasattr(real_dataset, 'dataset'):\n",
        "            real_dataset = real_dataset.dataset\n",
        "        self.balanced_max = 0\n",
        "        self.shuffle = shuffle\n",
        "        # Save all the indices for all the classes\n",
        "        for idx in range(0, len(dataset)):\n",
        "            label = self._get_label(real_dataset, idx)\n",
        "            if label not in self.dataset:\n",
        "                self.dataset[label] = list()\n",
        "            self.dataset[label].append(idx)\n",
        "            self.balanced_max = max(len(self.dataset[label]), self.balanced_max)\n",
        "\n",
        "        # Oversample the classes with fewer elements than the max\n",
        "        for label in self.dataset:\n",
        "            while len(self.dataset[label]) < self.balanced_max:\n",
        "                self.dataset[label].append(random.choice(self.dataset[label]))\n",
        "        self.keys = list(self.dataset.keys())\n",
        "        self.current_key = 0\n",
        "        self.indices = [-1]*len(self.keys)\n",
        "\n",
        "    @staticmethod\n",
        "    def _get_label(dataset, idx):\n",
        "        return dataset.imgs[idx][1]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.balanced_max*len(self.keys)\n",
        "\n",
        "    def __iter__(self):\n",
        "        if self.shuffle:\n",
        "            for key in self.keys:\n",
        "                random.shuffle(self.dataset[key])\n",
        "        while self.indices[self.current_key] < self.balanced_max - 1:\n",
        "            self.indices[self.current_key] += 1\n",
        "            label = self.keys[self.current_key]\n",
        "            index_label = self.indices[self.current_key]\n",
        "            yield self.dataset[label][index_label]\n",
        "            self.current_key = (self.current_key + 1) % len(self.keys)\n",
        "        self.indices = [-1]*len(self.keys)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPM2UAiV0cpL"
      },
      "source": [
        "### DataModule"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXy9kHAN8JV0"
      },
      "source": [
        "DEFAULT_BATCH_SIZE = 32\n",
        "DEFAULT_IMAGE_SIZE = (224, 224)\n",
        "STEPS = 1198 if minified else 2397\n",
        "\n",
        "class FlameDataModule(pl.LightningDataModule):\n",
        "    def __init__(\n",
        "            self,\n",
        "            batch_size=DEFAULT_BATCH_SIZE,\n",
        "            image_size=DEFAULT_IMAGE_SIZE\n",
        "        ):\n",
        "        super().__init__()\n",
        "        self.batch_size = batch_size\n",
        "        resize = T.Resize(image_size)\n",
        "        normalize = T.Normalize([0.485, 0.456, 0.406], \n",
        "                                [0.229, 0.224, 0.225])\n",
        "        toTensor = T.ToTensor()\n",
        "        self.train_transforms = T.Compose([\n",
        "            resize,\n",
        "            T.ColorJitter(brightness=0.1, contrast=0.1),\n",
        "            T.RandomRotation(degrees=45),\n",
        "            T.RandomHorizontalFlip(),\n",
        "            T.RandomVerticalFlip(),\n",
        "            toTensor,\n",
        "            normalize\n",
        "        ])\n",
        "        self.transforms = T.Compose([resize, toTensor, normalize])\n",
        "\n",
        "    def prepare_data(self):\n",
        "        self.data_dir = get_data_dir()\n",
        "    \n",
        "    def create_dataset(self, folder_name, transforms):\n",
        "        return ImageFolder(path.join(self.data_dir, folder_name), transforms)\n",
        "\n",
        "    def setup(self, stage=None):\n",
        "        if stage == 'fit' or stage is None:\n",
        "            self.train_ds = self.create_dataset('Training', self.train_transforms)\n",
        "            self.val_ds = self.create_dataset('Validation', self.transforms)\n",
        "        if stage == 'test' or stage is None:\n",
        "            self.test_ds = self.create_dataset('Test', self.transforms)\n",
        "\n",
        "    def _general_dataloader(self, dataset, **kwargs):\n",
        "        return DataLoader(\n",
        "            dataset, batch_size=self.batch_size, num_workers=2, drop_last=True,\n",
        "            pin_memory=True, **kwargs)\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        sampler = BalancedBatchSampler(self.train_ds, shuffle=True)\n",
        "        return self._general_dataloader(self.train_ds, sampler=sampler)\n",
        "        # print(len(loader))\n",
        "        # return loader\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return self._general_dataloader(self.val_ds)\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return self._general_dataloader(self.test_ds)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJCidcqFNrfU"
      },
      "source": [
        "datamodule = FlameDataModule()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F961Gb0ZUmm3"
      },
      "source": [
        "# Model \n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cd7xePlvUmm4"
      },
      "source": [
        "class PretrainedModel(pl.LightningModule):\n",
        "    def __init__(\n",
        "        self, name='rexnet_200', epochs=10, steps_per_epoch=100, lr=1e-3,\n",
        "        drop_rate=0.5, max_momentum=0.95\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.save_hyperparameters()\n",
        "        self.model = timm.create_model(name, pretrained=True,\n",
        "                                       num_classes=1, drop_rate=drop_rate)\n",
        "        self.just_train_classifier()\n",
        "\n",
        "        self.criterion = BCEWithLogitsLoss()\n",
        "        self.metrics = self.build_metrics()\n",
        "        self.transform = T.Compose([\n",
        "            T.RandomHorizontalFlip(),\n",
        "            T.RandomVerticalFlip()\n",
        "        ])\n",
        "    \n",
        "    def just_train_classifier(self):\n",
        "        self.freeze()\n",
        "        Freezer.make_trainable(self.model.get_classifier())\n",
        "\n",
        "    @staticmethod\n",
        "    def build_metrics():\n",
        "        general_metrics = [\n",
        "            Accuracy(compute_on_step=False),\n",
        "            F1(num_classes=2, compute_on_step=False)\n",
        "        ]\n",
        "        metric = MetricCollection(general_metrics)\n",
        "        return ModuleDict({\n",
        "            'test_metrics': metric.clone(),\n",
        "            'train_metrics': metric.clone(),\n",
        "            'val_metrics': metric.clone(),\n",
        "        })\n",
        "\n",
        "    def forward(self, x, tta = 0):\n",
        "        if tta == 0:\n",
        "            return self.model(x).squeeze(-1)\n",
        "        y_hat_stack = stack([self(self.transform(x)) for _ in range(tta)])\n",
        "        return y_hat_stack.mean(dim=0)\n",
        "    \n",
        "    def predict(self, x):\n",
        "        proba = sigmoid(self(x))\n",
        "        return (proba > 0.5).byte()\n",
        "\n",
        "    # Configurations\n",
        "    def configure_optimizers(self):\n",
        "        parameters = filter(lambda p: p.requires_grad, self.parameters())\n",
        "        optimizer = Adam(parameters, self.hparams.lr, weight_decay=1e-2)\n",
        "        # optimizer = Lookahead(optimizer)\n",
        "        scheduler = self._build_scheduler(optimizer)\n",
        "        scheduler_dict = {'scheduler': scheduler, 'interval': 'step'}\n",
        "        return [optimizer], [scheduler_dict]\n",
        "    \n",
        "    def _build_scheduler(self, optimizer):\n",
        "        lr, epochs = self.hparams.lr, self.hparams.epochs\n",
        "        max_momentum = self.hparams.max_momentum\n",
        "        base_momentum = max_momentum - 0.1\n",
        "        total_steps = epochs * self.hparams.steps_per_epoch\n",
        "        div_factor = epochs * 4\n",
        "        return OneCycleLR(\n",
        "            optimizer, lr, total_steps, pct_start=0.55, div_factor=div_factor,\n",
        "            final_div_factor=div_factor, three_phase=True,\n",
        "            max_momentum=max_momentum, base_momentum=base_momentum)\n",
        "\n",
        "    # Steps\n",
        "    def _get_dataset_metrics(self, dataset):\n",
        "        return self.metrics[f'{dataset}_metrics']\n",
        "\n",
        "    def _update_metrics(self, y_hat, y, dataset):\n",
        "        proba = sigmoid(y_hat)\n",
        "        self._get_dataset_metrics(dataset).update(proba, y)\n",
        "\n",
        "    def _on_step(self, batch, dataset):\n",
        "        x, y = batch\n",
        "        tta = 10 if dataset == 'test' else 0\n",
        "        y_hat = self(x, tta)\n",
        "        loss = self.criterion(y_hat, y.float())\n",
        "        self._update_metrics(y_hat, y, dataset)\n",
        "        self.log(f'{dataset}_loss', loss, prog_bar=True)\n",
        "        return loss\n",
        "\n",
        "    def _on_end_epochs(self, outputs, dataset):\n",
        "        labels = [f'{dataset}_acc', f'{dataset}_f1']\n",
        "        metrics = self._get_dataset_metrics(dataset)\n",
        "        metrics_values = metrics.compute().values()\n",
        "        for label, value in zip(labels, metrics_values):\n",
        "            self.log(label, value)\n",
        "        if dataset != 'train':\n",
        "            score = stack(list(metrics_values)).mean()\n",
        "            self.log(f'{dataset}_score', score, prog_bar=True)\n",
        "        metrics.reset()\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        return self._on_step(batch, 'train')\n",
        "    \n",
        "    def training_epoch_end(self, outputs):\n",
        "        self._on_end_epochs(outputs, 'train')\n",
        "    \n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        return self._on_step(batch, 'val')\n",
        "\n",
        "    def validation_epoch_end(self, outputs):\n",
        "        self._on_end_epochs(outputs, 'val')\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        return self._on_step(batch, 'test')\n",
        "\n",
        "    def test_epoch_end(self, outputs):\n",
        "        self._on_end_epochs(outputs, 'test')"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCJL6DnTCrwK"
      },
      "source": [
        "# Callbacks\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7UW7W-u0PXYy"
      },
      "source": [
        "## Freezer class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnP01wWyD60E"
      },
      "source": [
        "class Freezer(pl_callbacks.BaseFinetuning):\n",
        "    trainable_layers = []\n",
        "\n",
        "    def __init__(\n",
        "        self, steps=4, unfreeze_per_step=8, train_bn=False, epochs=40\n",
        "    ):\n",
        "        self.step_size = ceil(epochs / (steps + 1))\n",
        "        self.unfreeze_per_step = unfreeze_per_step\n",
        "        self.train_bn = train_bn\n",
        "\n",
        "    @staticmethod\n",
        "    def flatten_children(module):\n",
        "        vanilla_children = list(module.children())\n",
        "        if len(vanilla_children) == 0:\n",
        "            return [module]\n",
        "        children = []\n",
        "        for child in vanilla_children:\n",
        "            child_children = Freezer.flatten_children(child)\n",
        "            children += child_children\n",
        "        return children\n",
        "\n",
        "    @staticmethod\n",
        "    def filter_non_trainable(children):\n",
        "        calc_num_params = lambda module: sum(p.numel() for p in module.parameters())\n",
        "        has_params = lambda module: calc_num_params(module) > 0\n",
        "        return list(filter(has_params, children))\n",
        "    \n",
        "    @staticmethod\n",
        "    def filter_non_frozen(children):\n",
        "        requires_grad = lambda p: p.requires_grad\n",
        "        is_frozen_module = \\\n",
        "            lambda module: len(list(filter(requires_grad, module.parameters()))) == 0\n",
        "        return list(filter(is_frozen_module, children))\n",
        "\n",
        "    @staticmethod\n",
        "    def trainable_children(pl_module, train_bn=False, reverse=False):\n",
        "        children = Freezer.flatten_children(pl_module)\n",
        "        children = Freezer.filter_non_trainable(children)\n",
        "        children = Freezer.filter_non_frozen(children)\n",
        "        if not train_bn:\n",
        "            is_not_bn = lambda mod: not isinstance(mod, _BatchNorm) \n",
        "            children = list(filter(is_not_bn, children))\n",
        "        if reverse:\n",
        "            children.reverse()\n",
        "        return children\n",
        "    \n",
        "    def freeze_before_training(self, pl_module):\n",
        "        self.trainable_layers = self.trainable_children(\n",
        "            pl_module, self.train_bn, reverse=True)\n",
        "    \n",
        "    def finetune_function(self, pl_module, current_epoch, optimizer, optimizer_idx):\n",
        "        trainable_layers_len = len(self.trainable_layers)\n",
        "        is_empty = trainable_layers_len == 0\n",
        "        is_finetune_epoch = current_epoch % self.step_size == 0 and \\\n",
        "                         current_epoch != 0\n",
        "        if not is_finetune_epoch or is_empty:\n",
        "            return\n",
        "        to_be_trained_layers = []\n",
        "        layers_to_be_freeze = min(self.unfreeze_per_step, trainable_layers_len)\n",
        "        for _ in range(layers_to_be_freeze):\n",
        "            to_be_trained_layers.append(self.trainable_layers.pop(0))\n",
        "        self.unfreeze_and_add_param_group(\n",
        "            to_be_trained_layers, optimizer, swa=True, one_cycle=True)\n",
        "\n",
        "    @staticmethod\n",
        "    def unfreeze_and_add_param_group(\n",
        "        modules,\n",
        "        optimizer,\n",
        "        swa = False,\n",
        "        one_cycle = False,\n",
        "        lr = None,\n",
        "        initial_denom_lr = 10.,\n",
        "        train_bn = True,\n",
        "    ):\n",
        "        Freezer.make_trainable(modules)\n",
        "        params_lr = optimizer.param_groups[0]['lr'] if lr is None else float(lr)\n",
        "        denom_lr = initial_denom_lr if lr is None else 1.\n",
        "        initial_lr = params_lr / denom_lr\n",
        "        params = Freezer.filter_params(modules, train_bn=train_bn, requires_grad=True)\n",
        "        params = Freezer.filter_on_optimizer(optimizer, params)\n",
        "        if params:\n",
        "            param_group = {\n",
        "                'params': params, 'lr': initial_lr, 'initial_lr': initial_lr,\n",
        "            }\n",
        "            extra_data = {}\n",
        "            if one_cycle:\n",
        "                extra_data = Freezer.momentum_param_group(optimizer)\n",
        "            if swa:\n",
        "                extra_data = { 'swa_lr': initial_lr, **extra_data }\n",
        "            param_group = { **param_group, **extra_data }\n",
        "            optimizer.add_param_group(param_group)\n",
        "\n",
        "    @staticmethod\n",
        "    def momentum_param_group(optimizer):\n",
        "        group = optimizer.param_groups[0]\n",
        "        momentum_group = {\n",
        "            'base_momentum': group['base_momentum'],\n",
        "            'max_momentum': group['max_momentum'],\n",
        "            'max_lr': group['max_lr'],\n",
        "            'min_lr': group['min_lr'],\n",
        "        }\n",
        "        extra_group = {\n",
        "            'betas': group['betas']\n",
        "        } if 'betas' in optimizer.defaults else {\n",
        "            'momentum': group['momentum']\n",
        "        }\n",
        "        return { **momentum_group, **extra_group }"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kh9nEppHc2BG"
      },
      "source": [
        "## ProgressBar class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rV6ZiB0nc1Wk"
      },
      "source": [
        "class ProgressBar(pl_callbacks.ProgressBarBase):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.epoch_time = 0\n",
        "        self.stage_time = 0\n",
        "    \n",
        "    def disable(self):\n",
        "        pass\n",
        "    \n",
        "    def enable(self):\n",
        "        pass\n",
        "\n",
        "    @staticmethod\n",
        "    def format_num(n) -> str:\n",
        "        \"\"\" Add additional padding to the formatted numbers \"\"\"\n",
        "        should_be_padded = isinstance(n, (float, str))\n",
        "        if not isinstance(n, str):\n",
        "            n = tqdm.format_num(n)\n",
        "        if should_be_padded and 'e' not in n:\n",
        "            if '.' not in n and len(n) < 5:\n",
        "                try:\n",
        "                    _ = float(n)\n",
        "                except ValueError:\n",
        "                    return n\n",
        "                n += '.'\n",
        "            n += \"0\" * (5 - len(n))\n",
        "        return n\n",
        "    \n",
        "    def get_formatted_duration(self, prev_time):\n",
        "        duration = time() - prev_time\n",
        "        if duration < 60:\n",
        "            unit = 's'\n",
        "        elif duration < 3600:\n",
        "            duration /= 60\n",
        "            unit = 'm'\n",
        "        else:\n",
        "            duration /= 3600\n",
        "            unit = 'h'\n",
        "        return self.format_num(duration) + unit\n",
        "    \n",
        "    def on_train_start(self, trainer, pl_module):\n",
        "        self.stage_time = time()\n",
        "        print('Start training')\n",
        "\n",
        "    def on_train_end(self, trainer, pl_module):\n",
        "        print(f'Total duration: {self.get_formatted_duration(self.stage_time)}')\n",
        "    \n",
        "    def on_train_epoch_start(self, trainer, pl_module):\n",
        "        self.epoch_time = time()\n",
        "    \n",
        "    def on_validation_epoch_end(self, trainer, pl_module):\n",
        "        values = [\n",
        "            f'Epoch: {trainer.current_epoch}',\n",
        "            f'Time: {self.get_formatted_duration(self.epoch_time)}'\n",
        "        ]\n",
        "        values += [\n",
        "            f'{key}: {self.format_num(value)}'\n",
        "            for key, value in trainer.progress_bar_dict.items()\n",
        "        ]\n",
        "        print(' - '.join(values))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCOLnxQePb1b"
      },
      "source": [
        "## Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57HupS7lBJ4C"
      },
      "source": [
        "def get_checkpoint(model_name):\n",
        "    filename = '{epoch:02d}-{val_score:.4f}'\n",
        "    production_dirpath = path.join(get_model_dir(), model_name)\n",
        "    dirpath = production_dirpath if production_mode else model_name\n",
        "    return pl_callbacks.ModelCheckpoint(\n",
        "        dirpath=dirpath, monitor='val_score', mode='max', filename=filename)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StGH-GbjA99v"
      },
      "source": [
        "def get_callbacks(model_name, epochs):\n",
        "    checkpoint = get_checkpoint(model_name)\n",
        "    freezer = Freezer(epochs=epochs)\n",
        "    progress_bar = ProgressBar()\n",
        "    return [checkpoint, freezer, progress_bar]"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2t8iJ38PRaE"
      },
      "source": [
        "# Trainer\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4bdyXZPOn7-"
      },
      "source": [
        "def get_accelerator():\n",
        "    tpu_device_exists = xla_device.XLADeviceUtils().tpu_device_exists()\n",
        "    has_gpu = cuda.is_available()\n",
        "\n",
        "    return {'tpu_cores': 8} if tpu_device_exists else \\\n",
        "           {'gpus': cuda.device_count()} if has_gpu else {}"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jny1pcEGOpnN"
      },
      "source": [
        "max_epochs = 5\n",
        "production_mode = True\n",
        "\n",
        "def create_trainer(model_name, **kwargs):\n",
        "    callbacks = get_callbacks(model_name, max_epochs)\n",
        "    accelerator = get_accelerator()\n",
        "    return pl.Trainer(\n",
        "        max_epochs=max_epochs, deterministic=True, benchmark=True,\n",
        "        callbacks=callbacks, precision=16, stochastic_weight_avg=False,\n",
        "        **accelerator, **kwargs)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kEzlvDeNF3q"
      },
      "source": [
        "# Tuning\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_e34IyRNHnU"
      },
      "source": [
        "def find_best_and_substitute_lr(model, **kwargs):\n",
        "    trainer = create_trainer(model.hparams.name, auto_lr_find=True, **kwargs)\n",
        "    if trainer.fast_dev_run:\n",
        "        return\n",
        "    lr_finder = trainer.tuner.lr_find(\n",
        "        model, min_lr=1e-4, max_lr=9e-2, datamodule=datamodule,\n",
        "        num_training=480)\n",
        "    lr_finder.plot(suggest=True, show=True)\n",
        "    suggest_lr = lr_finder.results['lr'][lr_finder._optimal_idx]\n",
        "    model.hparams.lr = suggest_lr"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCeMVuy-A4Ri"
      },
      "source": [
        "# Training and testing\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GFiyQOl-jZi"
      },
      "source": [
        "def create_fit_and_test(model_name, **kwargs):\n",
        "    model = PretrainedModel(model_name, max_epochs, STEPS)\n",
        "    find_best_and_substitute_lr(model, **kwargs)\n",
        "    print(f'Training with max lr of {model.hparams.lr:.2e}')\n",
        "    trainer = create_trainer(model.hparams.name, **kwargs)\n",
        "    trainer.fit(model, datamodule=datamodule)\n",
        "    trainer.test(model, datamodule=datamodule)\n",
        "    cuda.empty_cache()"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5llRfok5hhwZ"
      },
      "source": [
        "# Models results\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IUetDolrkiD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "ff3380b109fa42a38cb66e8fe69c813a",
            "847a40bc4fcc45c8943a7fc464d28adb",
            "bca94177645b4c57bff6aadafcad9600",
            "16030d92526a4294aa56b4bd67ade72f",
            "5b135056553745859b4c431c42e1a8a1",
            "77d8cdf0742f4cda9ffb92b8c5c970ef",
            "867db44fed064babaee4eb978d8caabd",
            "3f1847058e394cb1b6d83fba63facd03"
          ]
        },
        "outputId": "97c69a46-5dd8-413f-efdc-0a76fe4d5ec7"
      },
      "source": [
        "create_fit_and_test('gernet_m')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU available: True, used: True\n",
            "TPU available: None, using: 0 TPU cores\n",
            "Using native 16bit precision.\n",
            "\n",
            "  | Name      | Type              | Params\n",
            "------------------------------------------------\n",
            "0 | model     | ByobNet           | 18.6 M\n",
            "1 | criterion | BCEWithLogitsLoss | 0     \n",
            "2 | metrics   | ModuleDict        | 0     \n",
            "------------------------------------------------\n",
            "2.6 K     Trainable params\n",
            "18.6 M    Non-trainable params\n",
            "18.6 M    Total params\n",
            "74.338    Total estimated model params size (MB)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ff3380b109fa42a38cb66e8fe69c813a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Finding best initial lr', max=400.0, style=ProgressStyle(…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Restored states from the checkpoint file at /content/lr_find_temp_model.ckpt\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "GPU available: True, used: True\n",
            "TPU available: None, using: 0 TPU cores\n",
            "Using native 16bit precision.\n",
            "\n",
            "  | Name      | Type              | Params\n",
            "------------------------------------------------\n",
            "0 | model     | ByobNet           | 18.6 M\n",
            "1 | criterion | BCEWithLogitsLoss | 0     \n",
            "2 | metrics   | ModuleDict        | 0     \n",
            "------------------------------------------------\n",
            "2.6 K     Trainable params\n",
            "18.6 M    Non-trainable params\n",
            "18.6 M    Total params\n",
            "74.338    Total estimated model params size (MB)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training with max lr of 3.12e-04\n",
            "Epoch: 0 - Time: 4.49e+5h - loss: nan.0 - v_num: 4 - val_loss: 0.749 - val_score: 0.0781\n",
            "Start training\n",
            "Epoch: 0 - Time: 2.250m - loss: 0.381 - v_num: 4 - val_loss: 0.391 - val_score: 0.895 - train_loss: 0.302\n",
            "Epoch: 1 - Time: 2.280m - loss: 0.0592 - v_num: 4 - val_loss: 0.0806 - val_score: 0.977 - train_loss: 0.00832\n",
            "Epoch: 2 - Time: 2.330m - loss: 0.080 - v_num: 4 - val_loss: 0.120 - val_score: 0.960 - train_loss: 0.0685\n",
            "Epoch: 3 - Time: 2.380m - loss: 0.0755 - v_num: 4 - val_loss: 0.104 - val_score: 0.960 - train_loss: 0.0344\n",
            "Epoch: 4 - Time: 2.420m - loss: 0.0727 - v_num: 4 - val_loss: 0.0721 - val_score: 0.977 - train_loss: 0.425\n",
            "Total duration: 11.70m\n",
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{'test_acc': 0.7876393795013428,\n",
            " 'test_f1': 0.7043028473854065,\n",
            " 'test_loss': 0.6329432129859924,\n",
            " 'test_score': 0.7459710836410522}\n",
            "--------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZfRQL75VVI2M"
      },
      "source": [
        "create_fit_and_test('repvgg_b0')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKeBxyitVglV"
      },
      "source": [
        "create_fit_and_test('rexnet_200')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fQ9TrlQV2PD"
      },
      "source": [
        "create_fit_and_test('tf_efficientnet_b4')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kerG8vMIuPie"
      },
      "source": [
        "# %load_ext tensorboard\n",
        "# %tensorboard --logdir /content/lightning_logs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QaZcJHqkfTYK"
      },
      "source": [
        "# !mv /content/lightning_logs /content/gdrive/MyDrive/Models/logs"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}